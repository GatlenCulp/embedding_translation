{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON to Parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm kinda just playing around with different datafiles here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor \u001b[38;5;28;01mas\u001b[39;00m T\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def create_training_logs_df():\n",
    "    \"\"\"Convert training logs into a structured dataframe\"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    # Recursively find all log.jsonl files\n",
    "    for log_file in Path(\"data\").rglob(\"**/log.jsonl\"):\n",
    "        # Get model pair info from parent directory\n",
    "        pair_info_file = log_file.parent / \"stitch_info_pairs.json\"\n",
    "        if not pair_info_file.exists():\n",
    "            continue\n",
    "\n",
    "        with open(pair_info_file) as f:\n",
    "            pair_info = json.load(f)\n",
    "\n",
    "        # Read log file\n",
    "        df = pl.read_ndjson(log_file)\n",
    "\n",
    "        # Add model pair info\n",
    "        df = df.with_columns(\n",
    "            [\n",
    "                pl.lit(pair_info[\"source\"]).alias(\"source_model\"),\n",
    "                pl.lit(pair_info[\"target\"]).alias(\"target_model\"),\n",
    "                pl.lit(pair_info[\"dataset\"]).alias(\"dataset\"),\n",
    "                pl.lit(pair_info[\"mode\"]).alias(\"architecture\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pl.concat(dfs)\n",
    "\n",
    "\n",
    "def create_model_metadata_df():\n",
    "    \"\"\"Create dataframe with model metadata\"\"\"\n",
    "    # Read CKA info\n",
    "    with open(\"data/cka_centered_natives/info.json\") as f:\n",
    "        cka_info = json.load(f)\n",
    "\n",
    "    # Convert model mappings to dataframe\n",
    "    models_df = pl.DataFrame(\n",
    "        {\n",
    "            \"model_id\": list(cka_info[\"model2idx\"].values()),\n",
    "            \"model_name\": list(cka_info[\"model2idx\"].keys()),\n",
    "            \"dataset_support\": list(cka_info[\"dataset2idx\"].keys()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return models_df\n",
    "\n",
    "\n",
    "def create_test_results_df():\n",
    "    \"\"\"Create dataframe with test results\"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    # Find all test visualization files\n",
    "    for test_file in Path(\"data/anal\").glob(\"test_visualize_*.json\"):\n",
    "        with open(test_file) as f:\n",
    "            test_data = json.load(f)\n",
    "\n",
    "        # Extract relevant test metrics\n",
    "        df = pl.DataFrame(\n",
    "            {\n",
    "                \"source_model\": test_data[\"data\"][\"source_embedding_model_name\"],\n",
    "                \"target_model\": test_data[\"data\"][\"target_embedding_model_name\"],\n",
    "                \"dataset\": test_data[\"data\"][\"text_dataset_name\"],\n",
    "                \"architecture\": test_data[\"data\"][\"architecture\"],\n",
    "                \"test_mse\": test_data[\"data\"][\"test_mse\"],\n",
    "                \"train_epochs\": test_data[\"data\"][\"train_status_final\"][\"num_epochs\"],\n",
    "                \"train_samples\": test_data[\"data\"][\"train_status_final\"][\n",
    "                    \"num_embeddings_trained_on_total\"\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pl.concat(dfs)\n",
    "\n",
    "\n",
    "# Create dataframes\n",
    "training_logs_df = create_training_logs_df()\n",
    "model_metadata_df = create_model_metadata_df()\n",
    "test_results_df = create_test_results_df()\n",
    "\n",
    "# Save as parquet files\n",
    "training_logs_df.write_parquet(\"data/processed/training_logs.parquet\")\n",
    "model_metadata_df.write_parquet(\"data/processed/model_metadata.parquet\")\n",
    "test_results_df.write_parquet(\"data/processed/test_results.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
