{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XXX XXX WHAT THE FUCK IS GOING ON WHAT THE FUCK IS GOING ON WHAT THE FUCK IS GOING ON (all the embeddings are the same?!) XXX XXX\n",
    "# # XXX turns out only some are fucked?\n",
    "# import torch\n",
    "# import safetensors\n",
    "# import pydantic\n",
    "# import safetensors.torch\n",
    "# from typing import Literal, Optional, List, Dict, Tuple\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "# DATASETS_PATH = Path(\"/mnt/align3_drive/adrianoh/dl_final_project_embeddings\")\n",
    "# NFCORPUS_PATH = DATASETS_PATH / \"nfcorpus\"\n",
    "# SCIDOCS_PATH = DATASETS_PATH / \"scidocs\"\n",
    "# FIQA_PATH = DATASETS_PATH / \"fiqa\"\n",
    "# ARGUANA_PATH = DATASETS_PATH / \"arguana\"\n",
    "\n",
    "# class EmbeddingDataset(pydantic.BaseModel):\n",
    "#     model_config = pydantic.ConfigDict(arbitrary_types_allowed=True)\n",
    "#     embeddings: torch.Tensor\n",
    "#     ids: List[str]\n",
    "#     documents: List[str]\n",
    "\n",
    "# [AFAIK DEPRECATED]\n",
    "# # XXX shit might not match because different models use different tokenizers so the chunks are different... FUCK\n",
    "# class EmbeddingLoader:\n",
    "#     def __init__(self, root_path: Path, allow_embedding_equality: bool = False):\n",
    "#         self.root_path = root_path\n",
    "#         self.allow_embedding_equality = allow_embedding_equality\n",
    "\n",
    "#     def fetch_embeddings(\n",
    "#         self,\n",
    "#         corpus_folder: Literal[\"corpus\", \"query\"] = \"corpus\",\n",
    "#         model_folders: Optional[List[str]] = None\n",
    "#     ) -> List[EmbeddingDataset]:\n",
    "#         \"\"\"\n",
    "#         Fetch the set of embeddings for the given corpus and subfolders.\n",
    "#         If it's `None` for `model_folders`, it will fetch all the models' embeddings.\n",
    "#         \"\"\"\n",
    "#         if model_folders is None:\n",
    "#             model_folders = [model_folder.name for model_folder in (self.root_path / corpus_folder).iterdir() if model_folder.is_dir()] # fmt: skip\n",
    "#         subpaths = [(self.root_path / corpus_folder / model_folder) for model_folder in model_folders]\n",
    "#         assert len(set(subpath.name for subpath in subpaths)) == len(subpaths)\n",
    "#         # The files we want\n",
    "#         embeddings_paths = [subpath / \"embeddings.safetensors\" for subpath in subpaths]\n",
    "#         ids_paths = [subpath / \"ids.json\" for subpath in subpaths]\n",
    "#         documents_paths = [subpath / \"documents.json\" for subpath in subpaths]\n",
    "#         chunks_paths = [subpath / \"chunks.json\" for subpath in subpaths]\n",
    "\n",
    "#         # They should all have the correct files present\n",
    "#         assert all(embeddings_path.exists() for embeddings_path in embeddings_paths), (\"Not all embeddings paths exist:\\n  \" + '\\n  '.join(f'{p.as_posix()}: {p.exists()}' for p in embeddings_paths)) # fmt: skip\n",
    "#         assert all(ids_path.exists() for ids_path in ids_paths), f\"Not all ids paths exist: {ids_paths}\"\n",
    "#         assert all(documents_path.exists() for documents_path in documents_paths), f\"Not all documents paths exist: {documents_paths}\" # fmt: skip\n",
    "#         assert all(chunks_path.exists() for chunks_path in chunks_paths), f\"Not all chunks paths exist: {chunks_paths}\" # fmt: skip\n",
    "\n",
    "#         _embeddings_sets: List[Dict[str, torch.Tensor]] = [safetensors.torch.load_file(embeddings_path, device=\"cpu\") for embeddings_path in embeddings_paths] # fmt: skip\n",
    "#         _ids_sets: List[Dict[str, List[str]]] = [json.load(open(ids_path, \"r\")) for ids_path in ids_paths]\n",
    "#         _documents_sets: List[Dict[str, List[str]]] = [json.load(open(documents_path, \"r\")) for documents_path in documents_paths] # fmt: skip\n",
    "#         _chunks_sets: List[Dict[str, List[str]]] = [json.load(open(chunks_path, \"r\")) for chunks_path in chunks_paths] # fmt: skip\n",
    "\n",
    "#         # Extrat the jsons\n",
    "#         assert all(isinstance(ids_set, dict) and \"ids\" in ids_set and len(ids_set) == 1 for ids_set in _ids_sets)\n",
    "#         assert all(isinstance(documents_set, dict) and \"documents\" in documents_set and len(documents_set) == 1 for documents_set in _documents_sets) # fmt: skip\n",
    "#         assert all(isinstance(embeddings_set, dict) and \"embeddings\" in embeddings_set and len(embeddings_set) == 1 for embeddings_set in _embeddings_sets) # fmt: skip\n",
    "#         assert all(isinstance(chunks_set, dict) and \"chunks\" in chunks_set and len(chunks_set) == 1 for chunks_set in _chunks_sets) # fmt: skip\n",
    "#         ids_sets: List[List[str]] = [ids_set[\"ids\"] for ids_set in _ids_sets]\n",
    "#         documents_sets: List[List[str]] = [documents_set[\"documents\"] for documents_set in _documents_sets] # fmt: skip\n",
    "#         embeddings_sets: List[torch.Tensor] = [embeddings_set[\"embeddings\"] for embeddings_set in _embeddings_sets] # fmt: skip\n",
    "#         chunks_sets: List[List[str]] = [chunks_set[\"chunks\"] for chunks_set in _chunks_sets] # fmt: skip\n",
    "\n",
    "#         # Make sure that all these have the same lengths\n",
    "#         _ids_lengths = [len(ids_set) for ids_set in ids_sets]\n",
    "#         _documents_lengths = [len(documents_set) for documents_set in documents_sets] # fmt: skip\n",
    "#         _embeddings_lengths = [len(embeddings_set) for embeddings_set in embeddings_sets] # fmt: skip\n",
    "#         _chunks_lengths = [len(chunks_set) for chunks_set in chunks_sets] # fmt: skip\n",
    "#         _nl = \"\\n\"\n",
    "#         assert len(subpaths) == len(_ids_lengths) == len(_documents_lengths) == len(_embeddings_lengths) == len(_chunks_lengths), f\"Got different lengths: {_nl.join(f'{i.as_posix()}: {l}' for i, l in zip(subpaths, _ids_lengths, _documents_lengths, _embeddings_lengths, _chunks_lengths))}\"\n",
    "#         assert len(set(_ids_lengths)) == 1, f\"Got different ids lengths: {_nl.join(f'{i.as_posix()}: {l}' for i, l in zip(subpaths, _ids_lengths))}\"\n",
    "#         assert len(set(_documents_lengths)) == 1, f\"Got different documents lengths: {_nl.join(f'{i.as_posix()}: {l}' for i, l in zip(subpaths, _documents_lengths))}\"\n",
    "#         assert len(set(_embeddings_lengths)) == 1, f\"Got different embeddings lengths: {_nl.join(f'{i.as_posix()}: {l}' for i, l in zip(subpaths, _embeddings_lengths))}\"\n",
    "#         assert len(set(_chunks_lengths)) == 1, f\"Got different chunks lengths: {_nl.join(f'{i.as_posix()}: {l}' for i, l in zip(subpaths, _chunks_lengths))}\"\n",
    "\n",
    "#         # Make sure the types are OK => they come from the same dataset but different models embedded so they should ONLY differ in that\n",
    "#         assert all(isinstance(ids_set, list) and all(isinstance(id, str) for id in ids_set) for ids_set in ids_sets) # fmt: skip\n",
    "#         assert all(ids_set1 == ids_sets[0] for ids_set1 in ids_sets) # star pattern for equality\n",
    "#         # ...\n",
    "#         assert all(isinstance(documents_set, list) and all(isinstance(doc, str) for doc in documents_set) for documents_set in documents_sets) # fmt: skip\n",
    "#         assert all(documents_set1 == documents_sets[0] for documents_set1 in documents_sets) # star pattern for equality\n",
    "#         #...\n",
    "#         assert all(isinstance(chunks_set, list) and all(isinstance(chunk, str) for chunk in chunks_set) for chunks_set in chunks_sets) # fmt: skip\n",
    "#         assert all(chunks_set1 == chunks_sets[0] for chunks_set1 in chunks_sets) # star pattern for equality\n",
    "#         # ...\n",
    "#         # (only the first dimension should match)\n",
    "#         assert all(isinstance(embeddings_set, torch.Tensor) and embeddings_set.shape[0] == embeddings_sets[0].shape[0] for embeddings_set in embeddings_sets) # fmt: skip\n",
    "#         # Cartesian product: all most be unique\n",
    "#         # avoid double-counting and self-comparison\n",
    "#         if not self.allow_embedding_equality:\n",
    "#             is_close: Dict[str, bool] = {}\n",
    "#             for i in range(len(embeddings_sets)):\n",
    "#                 for j in range(i + 1, len(embeddings_sets)):\n",
    "#                     path1, path2 = embeddings_paths[i].parent.name, embeddings_paths[j].parent.name\n",
    "#                     path_key = f\"{path1} <|> {path2}\"\n",
    "#                     is_close[path_key] = torch.allclose(embeddings_sets[i], embeddings_sets[j])\n",
    "#             is_close = {x : y for x, y in is_close.items() if y}\n",
    "#             assert len(is_close) == 0, f\"Got {len(is_close)} embeddings (total n_embeddings={len(embeddings_sets)}) that are the same:\\n\\n{json.dumps(is_close, indent=2)}\"\n",
    "#         return [\n",
    "#             EmbeddingDataset(\n",
    "#                 embeddings=embeddings_set,\n",
    "#                 ids=ids_set,\n",
    "#                 documents=documents_set\n",
    "#             )\n",
    "#             for embeddings_set, ids_set, documents_set in zip(embeddings_sets, ids_sets, documents_sets)\n",
    "#         ]\n",
    "\n",
    "# loader = EmbeddingLoader(root_path=NFCORPUS_PATH, allow_embedding_equality=False) # XXX this (the fact we allow True) is really unacceptable - something is WRONG and VERY WRONG ngl\n",
    "# embeddings_list: List[EmbeddingDataset] = loader.fetch_embeddings(corpus_folder=\"corpus\", model_folders=[\"intfloat_e5-large-v2\", \"thenlper_gte-small\"]) # get all the document/corpus embeddings\n",
    "# print(\"Embeddings shape is\", embeddings_list[0].embeddings.shape, \"=\", embeddings_list[1].embeddings.shape, \"= ...\") # axis 0 is dataset, axis 1 is embedding\n",
    "# print(\"Embeddings devices:\", \"embeddings1.device\", embeddings_list[0].embeddings.device, \"embeddings2.device\", embeddings_list[1].embeddings.device, \"etc...\") # shoulds be cpu cpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the necessary pydantic structures where we will store everything. Everything will be in:\n",
    "    <model1_folderable_name>_<model2_folderable_name>/\n",
    "        <dataset_name>/\n",
    "            # Linear transform\n",
    "            linear_transform.safetensors\n",
    "            stitch_info.json\n",
    "            # Embeddings (generated via linear(model1(texts))) where linear maps from model1 space to model2 space\n",
    "            embeddings_corpus_train.safetensors\n",
    "            embeddings_corpus_validation.safetensors\n",
    "            embeddings_query_train.safetensors\n",
    "            embeddings_query_validation.safetensors\n",
    "            # Metadatas\n",
    "            metadatas_corpus_train.json\n",
    "            metadatas_corpus_validation.json\n",
    "            metadatas_query_train.json\n",
    "            metadatas_query_validation.json\n",
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "import safetensors\n",
    "import pydantic\n",
    "import safetensors.torch\n",
    "from typing import Literal, Optional, List, Dict, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class StitchPair(BaseModel):\n",
    "    source: str\n",
    "    target: str\n",
    "    dataset: str\n",
    "    mode: Literal[\"affine\"] = \"affine\"  # TODO(Adriano) later we will support more shit here\n",
    "\n",
    "    def save_linear_transform(self, linear: nn.Linear, save_path: Path) -> None:\n",
    "        linear_path = save_path / \"linear_transform.safetensors\"\n",
    "        stitch_info_path = save_path / \"stitch_info.json\"\n",
    "        assert not linear_path.exists(), f\"Linear transform already exists at {linear_path}\"\n",
    "        assert not stitch_info_path.exists(), f\"Stitch info already exists at {stitch_info_path}\"\n",
    "        safetensors.torch.save_file(linear.state_dict(), linear_path)\n",
    "        stitch_info_path.write_text(self.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can try to train linear transforms between embeddings...\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "from pydantic import BaseModel\n",
    "import wandb\n",
    "from typing import Optional\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, source_embeddings: torch.Tensor, target_embeddings: torch.Tensor):\n",
    "        assert source_embeddings.shape[0] == target_embeddings.shape[0]\n",
    "        self.source_embeddings = source_embeddings\n",
    "        self.target_embeddings = target_embeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_embeddings)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_embeddings[idx], self.target_embeddings[idx]\n",
    "\n",
    "class LinearTransformTrainerArgs(BaseModel):\n",
    "    # We use default for now :)\n",
    "    test_split: float = 0.2\n",
    "    num_epochs: int = 50\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.001\n",
    "    save_every_n_epochs: int = 10\n",
    "    use_tqdm: bool = True\n",
    "\n",
    "class LinearTransformTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        save_path: Path,\n",
    "        linear: Optional[nn.Linear],\n",
    "        source_embeddings_train: torch.Tensor,\n",
    "        target_embeddings_train: torch.Tensor,\n",
    "        source_embeddings_validation: torch.Tensor,\n",
    "        target_embeddings_validation: torch.Tensor,\n",
    "        device: torch.device | str,\n",
    "        args: LinearTransformTrainerArgs = LinearTransformTrainerArgs()\n",
    "    ):\n",
    "        self.linear = linear\n",
    "        self.source_embeddings_train = source_embeddings_train\n",
    "        self.target_embeddings_train = target_embeddings_train\n",
    "        self.source_embeddings_validation = source_embeddings_validation\n",
    "        self.target_embeddings_validation = target_embeddings_validation\n",
    "        self.num_epochs = args.num_epochs\n",
    "        self.batch_size = args.batch_size\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.device = device\n",
    "        self.test_split = args.test_split\n",
    "        self.save_every_n_epochs = args.save_every_n_epochs\n",
    "        self.save_path = save_path\n",
    "        self.checkpoint_path = save_path / \"checkpoints\"\n",
    "        self.checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.logfile = save_path / \"log.jsonl\"\n",
    "        self.use_tqdm = args.use_tqdm\n",
    "        if self.linear is None:\n",
    "            self.linear = self.create_linear_transform()\n",
    "        self.optimizer = torch.optim.Adam(self.linear.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    #### PRE-TRAINING HELPERS ####\n",
    "    def create_datasets(self):\n",
    "        # Create indices and shuffle\n",
    "        # num_samples = len(self.source_embeddings_train)\n",
    "        # indices = torch.randperm(num_samples)\n",
    "        \n",
    "        # Split indices -> NOTE we already created this shit\n",
    "        # split_idx = int(num_samples * (1 - self.test_split))\n",
    "        # train_indices = indices[:split_idx]\n",
    "        # test_indices = indices[split_idx:]\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = EmbeddingDataset(\n",
    "            self.source_embeddings_train,\n",
    "            self.target_embeddings_train\n",
    "        )\n",
    "        test_dataset = EmbeddingDataset(\n",
    "            self.source_embeddings_validation,\n",
    "            self.target_embeddings_validation\n",
    "        )\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def create_linear_transform(self):\n",
    "        return nn.Linear(self.source_embeddings_train.shape[1], self.target_embeddings_train.shape[1]).to(self.device)\n",
    "\n",
    "    #### TRAINING HELPERS ####\n",
    "    def train(self):\n",
    "        train_dataset, test_dataset = self.create_datasets()\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "        mse_loss = nn.MSELoss()\n",
    "        trange = tqdm.trange if self.use_tqdm else range\n",
    "        tqdm_fn = tqdm.tqdm if self.use_tqdm else lambda *args, **kwargs: args[0]\n",
    "        for epoch in trange(self.num_epochs):\n",
    "            # Training\n",
    "            self.linear.train()\n",
    "            train_mse = 0.0\n",
    "            train_mae = 0.0\n",
    "            num_train_batches = 0\n",
    "\n",
    "            for source_emb, target_emb in train_loader:\n",
    "                source_emb = source_emb.to(self.device)\n",
    "                target_emb = target_emb.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.linear(source_emb)\n",
    "\n",
    "                loss = mse_loss(output, target_emb)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_mse += loss.detach().item()\n",
    "                train_mae += (output.detach() - target_emb.detach()).abs().mean().item()\n",
    "                num_train_batches += 1\n",
    "\n",
    "            avg_train_mse = train_mse / num_train_batches\n",
    "            avg_train_mae = train_mae / num_train_batches\n",
    "\n",
    "            # Evaluation\n",
    "            self.linear.eval()\n",
    "            test_mse = 0.0\n",
    "            test_mae = 0.0\n",
    "            num_test_batches = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for source_emb, target_emb in tqdm_fn(test_loader):\n",
    "                    source_emb = source_emb.to(self.device)\n",
    "                    target_emb = target_emb.to(self.device)\n",
    "\n",
    "                    output = self.linear(source_emb)\n",
    "\n",
    "                    test_mse += mse_loss(output, target_emb).item()\n",
    "                    test_mae += (output.detach() - target_emb.detach()).abs().mean().item()\n",
    "                    num_test_batches += 1\n",
    "\n",
    "            avg_test_mse = test_mse / num_test_batches\n",
    "            avg_test_mae = test_mae / num_test_batches\n",
    "\n",
    "            # Log metrics\n",
    "            log_entry = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_mse\": avg_train_mse,\n",
    "                \"train_mae\": avg_train_mae,\n",
    "                \"test_mse\": avg_test_mse,\n",
    "                \"test_mae\": avg_test_mae,\n",
    "            }\n",
    "            wandb.log(log_entry)\n",
    "            with open(self.logfile, \"a\") as f:\n",
    "                f.write(json.dumps(log_entry) + \"\\n\")\n",
    "\n",
    "            if epoch % self.save_every_n_epochs == 0:\n",
    "                self.save_checkpoint(epoch)\n",
    "\n",
    "    def save_checkpoint(self, epoch: int):\n",
    "        checkpoint_path = self.checkpoint_path / f\"checkpoint_{epoch}.safetensors\"\n",
    "        safetensors.torch.save_file(self.linear.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ARGS = LinearTransformTrainerArgs(\n",
    "    test_split=0.2,\n",
    "    num_epochs=50,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.001,\n",
    "    save_every_n_epochs=10,\n",
    "    use_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m4gate\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_210616-hywjun6h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train/runs/hywjun6h' target=\"_blank\">ipynb_test_dec_10</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train/runs/hywjun6h' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train/runs/hywjun6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 3117.71it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.73it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3146.78it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3164.83it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3119.83it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3155.82it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3174.14it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3234.74it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3153.88it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.69it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3195.28it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3150.09it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3144.43it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3153.41it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.87it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3191.77it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 2885.32it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3140.09it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.93it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3172.73it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3143.89it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3164.76it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3148.34it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3124.81it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3185.92it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.95it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3169.07it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3163.13it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3107.91it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.13it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 2872.19it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3141.26it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3162.27it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3146.24it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3142.54it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 2991.05it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3007.35it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3028.00it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3011.45it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3048.15it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3038.28it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3015.41it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3078.78it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3050.18it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 2975.68it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.40it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3035.36it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3035.71it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.16it/s]\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.89it/s]\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mse</td><td>█▄▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00841</td></tr><tr><td>test_mse</td><td>0.00011</td></tr><tr><td>train_mae</td><td>0.00799</td></tr><tr><td>train_mse</td><td>0.0001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ipynb_test_dec_10</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train/runs/hywjun6h' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train/runs/hywjun6h</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_testing_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_210616-hywjun6h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Single layer train attempt. This should help us get some good data.\n",
    "\"\"\"\n",
    "import click\n",
    "import os\n",
    "import shutil\n",
    "from safetensors.torch import load_file\n",
    "save_path_parent = Path(\"/mnt/align3_drive/adrianoh/dl_final_project_layers\")\n",
    "embeddings1_path = Path(\"/mnt/align3_drive/adrianoh/dl_final_project_embeddings_huggingface/intfloat_e5-base-v2/arguana\")\n",
    "embeddings2_path = Path(\"/mnt/align3_drive/adrianoh/dl_final_project_embeddings_huggingface/thenlper_gte-base/arguana\")\n",
    "# work only on corpus right now\n",
    "embeddings1_train = load_file(embeddings1_path / \"embeddings_corpus_train.safetensors\")[\"embeddings\"] # X\n",
    "embeddings1_validation = load_file(embeddings1_path / \"embeddings_corpus_validation.safetensors\")[\"embeddings\"] # Y\n",
    "embeddings2_train = load_file(embeddings2_path / \"embeddings_corpus_train.safetensors\")[\"embeddings\"] # x\n",
    "embeddings2_validation = load_file(embeddings2_path / \"embeddings_corpus_validation.safetensors\")[\"embeddings\"] # y\n",
    "assert embeddings1_train.shape[0] == embeddings2_train.shape[0]\n",
    "assert embeddings1_validation.shape[0] == embeddings2_validation.shape[0]\n",
    "\n",
    "save_path = save_path_parent / \"ipynb_test\"\n",
    "assert os.environ.get(\"CUDA_VISIBLE_DEVICES\") is None\n",
    "if save_path.exists():\n",
    "    click.echo(f\"Save path {save_path} already exists. Deleting it...\")\n",
    "    # click.confirm(f\"Save path {save_path} already exists. Do you want to delete it?\", abort=True)\n",
    "    shutil.rmtree(save_path)\n",
    "device = \"cuda:0\" # change this based on availability\n",
    "wandb.init(project=\"2024_12_09_dl_project_testing_layer_train\", name=\"ipynb_test_dec_10\")\n",
    "trainer = LinearTransformTrainer(\n",
    "    save_path=save_path, # made by the trainer\n",
    "    linear=None, # trainer makes it\n",
    "    source_embeddings_train=embeddings1_train.to(device),\n",
    "    target_embeddings_train=embeddings2_train.to(device),\n",
    "    source_embeddings_validation=embeddings1_validation.to(device),\n",
    "    target_embeddings_validation=embeddings2_validation.to(device),\n",
    "    device=device,\n",
    "    args=DEFAULT_ARGS\n",
    ")\n",
    "trainer.train()\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [AFAIK DEPRECATED] => all ingestion settings etc... are default\n",
    "# class EmbeddingMetadata(pydantic.BaseModel):\n",
    "#     \"\"\"ChromaDB embedding metadata.\n",
    "\n",
    "#     Every embedding in a ChromaDB collection has a metadata object that explains\n",
    "#     basically whether its a query or a document.\n",
    "#     \"\"\"\n",
    "\n",
    "#     record_id: str\n",
    "#     chunk_id: str\n",
    "#     chunk_text: str\n",
    "#     record_text: str | None = None  # <---- like never used tbh\n",
    "#     record_type: Literal[\"query\", \"document\"]\n",
    "#     # TODO(Adriano) not everything should be train by default\n",
    "#     record_split: Literal[\"train\", \"test\"] = \"train\"\n",
    "#     tags: dict[str, str] | None = {}  # <---- should insert some meaning tags for umap cluster\n",
    "\n",
    "# class IngestionSettings(BaseModel):\n",
    "#     \"\"\"Equivalent to owler's .env file.\n",
    "\n",
    "#     Used to define how to process the ingestion of the textual data into chromaDB\n",
    "#     \"\"\"\n",
    "\n",
    "#     chunk_size: int = 256\n",
    "#     device: str | None = None  # does not matter\n",
    "#     distance_function: str | None = None  # does not matter\n",
    "#     normalize_embeddings: bool | None = None  # does not matter\n",
    "#     # TODO(Adriano) in the future we will want to try passing this through a model before\n",
    "#     chunk_preprocessing_mode: Literal[\"add_prefix\"] = \"add_prefix\"\n",
    "#     query_preprocessing_mode: Literal[\"add_prefix\"] = \"add_prefix\"\n",
    "#     chunk_prefix: str = (\n",
    "#         \"passage: \"  # Can be used to add prefix to text embeddings stored in vector store\n",
    "#     )\n",
    "#     query_prefix: str = (\n",
    "#         \"query: \"  # Can be used to add prefix to text embeddings used for semantic search\n",
    "#     )\n",
    "#     chunk_overlap: int = 25  # Determines, for a given chunk of text, how many tokens must overlap with adjacent chunks.\n",
    "#     dataloader_batch_size: int = 32\n",
    "#     dataloader_num_workers: int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelMetadata(BaseModel):\n",
    "#     \"\"\"Metadata for a single model's embeddings.\"\"\"\n",
    "#     model: str\n",
    "#     dataset: str = \"default\"\n",
    "#     chunk_size: int = 256\n",
    "#     query_prefix: str | None = None\n",
    "#     document_prefix: str | None = None\n",
    "\n",
    "# class TransformMetadata(BaseModel):\n",
    "#     \"\"\"Metadata for a transform between two models.\"\"\"\n",
    "#     source_model: ModelMetadata\n",
    "#     target_model: ModelMetadata\n",
    "import itertools\n",
    "DATASETS = [\n",
    "    # (numbers are counts for documents, there may be some longer documents -> slightly more chunks)\n",
    "    \"arguana\", # 10K\n",
    "    \"fiqa\", # 50K -> 20K\n",
    "    \"scidocs\", # 25K -> 20K\n",
    "    \"nfcorpus\", # 5K\n",
    "    \"hotpotqa\", # 100K -> 20K\n",
    "    \"trec-covid\", # too much -> 20K\n",
    "]\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"Salesforce/SFR-Embedding-Mistral\",\n",
    "    \"WhereIsAI/UAE-Large-V1\",\n",
    "    \"BAAI/bge-base-en-v1.5\",\n",
    "    \"BAAI/bge-large-en-v1.5\",\n",
    "    \"BAAI/bge-small-en-v1.5\",\n",
    "    \"intfloat/e5-base-v2\",\n",
    "    \"intfloat/e5-large-v2\",\n",
    "    \"intfloat/e5-small-v2\",\n",
    "    \"thenlper/gte-base\",\n",
    "    \"thenlper/gte-large\",\n",
    "    \"thenlper/gte-small\",\n",
    "    \"sentence-transformers/gtr-t5-base\",\n",
    "    \"sentence-transformers/gtr-t5-large\",\n",
    "    \"mixedbread-ai/mxbai-embed-large-v1\",\n",
    "    \"sentence-transformers/sentence-t5-base\",\n",
    "    \"sentence-transformers/sentence-t5-large\",\n",
    "    \"text-embedding-3-large\", # openai\n",
    "    \"text-embedding-3-small\", # openai\n",
    "]\n",
    "\n",
    "class EmbeddingTransformTrainer:\n",
    "    \"\"\"Handles training transforms between embedding models.\"\"\"\n",
    "    \n",
    "    def __init__(self, save_path_parent: Path, load_path_parent: Path, device: str, wandb_project: str):\n",
    "        self.save_path_parent = save_path_parent\n",
    "        self.load_path_parent = load_path_parent\n",
    "        self.device = device\n",
    "        self.wandb_project = wandb_project\n",
    "        \n",
    "    def train_all_pairs(\n",
    "        self,\n",
    "        filter_against_model: List[str] = [],\n",
    "        filter_for_model: List[str] = [],\n",
    "        filter_for_dataset: List[str] = [],\n",
    "        filter_against_dataset: List[str] = []\n",
    "    ):\n",
    "        \"\"\"Train transforms between all pairs of embeddings.\"\"\"\n",
    "        # filtering...\n",
    "        combos = list(itertools.product(DATASETS, MODEL_NAMES, MODEL_NAMES))\n",
    "        combos = [x for x in combos if x[1] != x[2]]\n",
    "        # 1. filter for models\n",
    "        for filter_against_model in filter_against_model:\n",
    "            combos = [x for x in combos if filter_against_model not in x[1] and filter_against_model not in x[2]]\n",
    "        for filter_for_model in filter_for_model:\n",
    "            combos = [x for x in combos if filter_for_model in x[1] and filter_for_model in x[2]]\n",
    "        # 2. filter for datasets\n",
    "        for filter_for_dataset in filter_for_dataset:\n",
    "            combos = [x for x in combos if filter_for_dataset in x[0]]\n",
    "        for filter_against_dataset in filter_against_dataset:\n",
    "            combos = [x for x in combos if filter_against_dataset not in x[0]]\n",
    "        # End filtering...\n",
    "        print(f\"Training {len(combos)} transforms\")\n",
    "        for dataset, src, dest in tqdm.tqdm(combos, desc=\"Training transforms (all default settings)\"):\n",
    "            assert src != dest\n",
    "            # plz plz\n",
    "            src_name_ok = src.replace(\"/\", \"_\")\n",
    "            dest_name_ok = dest.replace(\"/\", \"_\")\n",
    "            dataset_ok = dataset.replace(\"/\", \"_\")\n",
    "\n",
    "            # 1. make sure shit is present in load\n",
    "            embeddings1_path = self.load_path_parent / src_name_ok / dataset_ok\n",
    "            embeddings2_path = self.load_path_parent / dest_name_ok / dataset_ok\n",
    "            # NOTE ====> only corpus right now\n",
    "            embeddings1_train_path = embeddings1_path / \"embeddings_corpus_train.safetensors\"\n",
    "            embeddings1_validation_path = embeddings1_path / \"embeddings_corpus_validation.safetensors\"\n",
    "            embeddings2_train_path = embeddings2_path / \"embeddings_corpus_train.safetensors\"\n",
    "            embeddings2_validation_path = embeddings2_path / \"embeddings_corpus_validation.safetensors\"\n",
    "            if any(not x.exists() for x in [embeddings1_train_path, embeddings1_validation_path, embeddings2_train_path, embeddings2_validation_path]):\n",
    "                print(f\"Skipping {src} to {dest} because some files do not exist in {embeddings1_path.name} or {embeddings2_path.name}\")\n",
    "                for file in [embeddings1_train_path, embeddings1_validation_path, embeddings2_train_path, embeddings2_validation_path]:\n",
    "                    if file.exists():\n",
    "                        print(f\"File {file} exists\")\n",
    "                    else:\n",
    "                        print(f\"File {file} does not exist\")\n",
    "                continue\n",
    "\n",
    "            # 2. make sure shit is NOT present in save\n",
    "            save_parent = self.save_path_parent / f\"{src_name_ok}_{dest_name_ok}\" / dataset_ok\n",
    "            stitch_info_pair_file = save_parent / \"stitch_info_pairs.jsonl\"\n",
    "            linear_transform_file = save_parent / \"linear_transform.safetensors\"\n",
    "            assert not linear_transform_file.exists()\n",
    "            assert not stitch_info_pair_file.exists()\n",
    "            save_parent.mkdir(parents=True, exist_ok=True)\n",
    "            stitch_info_pair = StitchPair(\n",
    "                source=src,\n",
    "                target=dest,\n",
    "                dataset=dataset\n",
    "            )\n",
    "            stitch_info_pair_file.write_text(stitch_info_pair.model_dump_json())\n",
    "\n",
    "            # 3. load\n",
    "            embeddings1_train = load_file(embeddings1_train_path)[\"embeddings\"] # X\n",
    "            embeddings1_validation = load_file(embeddings1_validation_path)[\"embeddings\"] # Y\n",
    "            embeddings2_train = load_file(embeddings2_train_path)[\"embeddings\"] # x\n",
    "            embeddings2_validation = load_file(embeddings2_validation_path)[\"embeddings\"] # y\n",
    "            # Initialize wandb run\n",
    "            wandb.init(\n",
    "                project=self.wandb_project,\n",
    "                name=f\"{src_name_ok}_{dest_name_ok}\",\n",
    "                reinit=True\n",
    "            )\n",
    "            # Train the model\n",
    "            trainer = LinearTransformTrainer(\n",
    "                save_path=save_path,\n",
    "                linear=None,\n",
    "                source_embeddings_train=embeddings1_train.to(self.device),\n",
    "                target_embeddings_train=embeddings2_train.to(self.device),\n",
    "                source_embeddings_validation=embeddings1_validation.to(self.device),\n",
    "                target_embeddings_validation=embeddings2_validation.to(self.device),\n",
    "                device=self.device,\n",
    "                args=DEFAULT_ARGS\n",
    "            )\n",
    "            trainer.train()\n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 210 transforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   0%|          | 0/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4zvzgqqg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">intfloat_e5-small-v2_WhereIsAI_UAE-Large-V1</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/4zvzgqqg' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/4zvzgqqg</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215458-4zvzgqqg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4zvzgqqg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215829-htmy54je</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/htmy54je' target=\"_blank\">WhereIsAI_UAE-Large-V1_BAAI_bge-base-en-v1.5</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/htmy54je' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/htmy54je</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3146.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3169.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3107.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3096.57it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3130.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3147.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.87it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.27it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3168.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3157.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3179.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3118.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.92it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3104.10it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.92it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3115.93it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3096.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3103.15it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3077.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3101.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3085.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3109.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3134.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3148.57it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3114.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3103.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2940.92it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3143.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3090.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3091.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.27it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3114.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3040.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3088.56it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.47it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▂▃▂▂▂▁▂▁▁▂▁▁▁▁▁▁▂▁▁▂▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▁▁▂▂▁▁▂▂▂▂▂▂▂▁▂</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01251</td></tr><tr><td>test_mse</td><td>0.00025</td></tr><tr><td>train_mae</td><td>0.01162</td></tr><tr><td>train_mse</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_BAAI_bge-base-en-v1.5</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/htmy54je' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/htmy54je</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215829-htmy54je/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   0%|          | 1/210 [00:15<54:29, 15.64s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215845-fdp3e7hq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/fdp3e7hq' target=\"_blank\">WhereIsAI_UAE-Large-V1_BAAI_bge-large-en-v1.5</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/fdp3e7hq' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/fdp3e7hq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3073.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3048.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.01it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3085.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2936.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3095.49it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3048.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3090.31it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3052.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3076.39it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3052.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3075.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3026.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3060.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3050.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3079.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3057.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3057.33it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3039.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3051.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3072.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3066.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3015.47it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3019.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.43it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3079.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3084.37it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3043.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3070.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3019.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3052.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3072.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3053.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3042.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3052.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3018.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2992.72it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3109.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3111.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3078.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3044.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3090.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3023.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3091.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3021.86it/s]\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00353</td></tr><tr><td>test_mse</td><td>2e-05</td></tr><tr><td>train_mae</td><td>0.0033</td></tr><tr><td>train_mse</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_BAAI_bge-large-en-v1.5</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/fdp3e7hq' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/fdp3e7hq</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215845-fdp3e7hq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   1%|          | 2/210 [00:30<53:12, 15.35s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215900-qcmz8z7u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qcmz8z7u' target=\"_blank\">WhereIsAI_UAE-Large-V1_BAAI_bge-small-en-v1.5</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qcmz8z7u' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qcmz8z7u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2977.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2945.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2948.28it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2816.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2979.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2946.65it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2953.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2993.98it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2983.72it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3011.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2879.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2996.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2979.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2931.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2979.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2966.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2941.93it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2956.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2981.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2978.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2996.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2943.05it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2952.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3009.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3012.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2963.33it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2957.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3006.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2992.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2973.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2990.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2996.57it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2957.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3021.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2939.10it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3032.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2990.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2972.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2879.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3001.47it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2964.47it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2953.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3018.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2984.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2968.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2981.00it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▄▃▂▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>test_mse</td><td>█▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01669</td></tr><tr><td>test_mse</td><td>0.00044</td></tr><tr><td>train_mae</td><td>0.01546</td></tr><tr><td>train_mse</td><td>0.00038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_BAAI_bge-small-en-v1.5</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qcmz8z7u' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qcmz8z7u</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215900-qcmz8z7u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   1%|▏         | 3/210 [00:46<53:15, 15.44s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215916-qo24cuk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qo24cuk5' target=\"_blank\">WhereIsAI_UAE-Large-V1_intfloat_e5-base-v2</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qo24cuk5' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qo24cuk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.65it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3056.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3064.57it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.74it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3068.83it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3058.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3078.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3102.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3109.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3069.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3056.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3054.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3091.74it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3058.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3033.29it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3078.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3103.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3067.49it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3076.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3068.96it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3070.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3049.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3156.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3118.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2999.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3126.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2948.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.72it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3102.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3130.11it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3078.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3138.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3144.96it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2990.83it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2909.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3123.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3148.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3117.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3123.28it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3049.10it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3156.53it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▂▃▁▁▂▂▁▁▁▁▂▂▁▁▂▁▁▂▁▂▁▁▂▁▁▁▁▂▂▁▂▂▂▁▂▂▂</td></tr><tr><td>test_mse</td><td>█▄▃▂▂▁▂▂▂▁▁▁▁▁▂▁▁▂▂▁▁▂▁▂▁▂▁▁▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01034</td></tr><tr><td>test_mse</td><td>0.00017</td></tr><tr><td>train_mae</td><td>0.00962</td></tr><tr><td>train_mse</td><td>0.00015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_intfloat_e5-base-v2</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qo24cuk5' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/qo24cuk5</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215916-qo24cuk5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   2%|▏         | 4/210 [01:02<53:22, 15.54s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215931-7z554pl4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/7z554pl4' target=\"_blank\">WhereIsAI_UAE-Large-V1_intfloat_e5-large-v2</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/7z554pl4' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/7z554pl4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3085.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3087.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3124.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3079.23it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3106.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3076.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3105.87it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3070.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2976.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3118.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3069.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3075.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3125.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3104.40it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3073.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3037.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3117.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3090.96it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3077.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3112.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3141.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3077.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.40it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2959.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3077.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.11it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3059.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3047.93it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3104.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3084.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.84it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3067.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.33it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00948</td></tr><tr><td>test_mse</td><td>0.00014</td></tr><tr><td>train_mae</td><td>0.00885</td></tr><tr><td>train_mse</td><td>0.00012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_intfloat_e5-large-v2</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/7z554pl4' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/7z554pl4</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215931-7z554pl4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   2%|▏         | 5/210 [01:18<53:58, 15.80s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_215948-ax4040jy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/ax4040jy' target=\"_blank\">WhereIsAI_UAE-Large-V1_intfloat_e5-small-v2</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/ax4040jy' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/ax4040jy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3007.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2980.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2995.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2979.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2967.98it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2982.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3026.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2988.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2971.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2988.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2992.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3049.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2987.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3022.05it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2970.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2998.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2996.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3023.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2997.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3035.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2988.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3023.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3031.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3003.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2968.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2934.19it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2978.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2978.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2941.31it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2951.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2981.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3023.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2964.80it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2981.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2956.65it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3000.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2944.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2922.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2939.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2966.84it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2946.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3024.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2956.92it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2964.56it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2945.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2975.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2990.16it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▂▂▂▂▂▁▂▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▂▂▂▂▁▁▂▂▁▂▁</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▂▂▂▁▁▂▂▁▂▁</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.0136</td></tr><tr><td>test_mse</td><td>0.00029</td></tr><tr><td>train_mae</td><td>0.01265</td></tr><tr><td>train_mse</td><td>0.00025</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_intfloat_e5-small-v2</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/ax4040jy' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/ax4040jy</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_215948-ax4040jy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   3%|▎         | 6/210 [01:32<51:44, 15.22s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220002-2611fre7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/2611fre7' target=\"_blank\">WhereIsAI_UAE-Large-V1_thenlper_gte-base</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/2611fre7' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/2611fre7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3134.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3053.77it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2960.29it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3128.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3152.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3062.65it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3022.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3067.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3139.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3074.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3140.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3145.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3146.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3110.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3101.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3107.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.26it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3155.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3094.74it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3121.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3095.56it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2964.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3081.98it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3113.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3157.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3133.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3106.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3095.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3085.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3141.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3156.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3154.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3087.35it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 1945.35it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3111.37it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3072.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3101.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3120.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3118.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.11it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3112.43it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3137.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3087.74it/s]\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▃▂▂▂▂▂▂▁▂▁▂▁▁▂▂▁▁▂▂▂▂▁▂▂▂▂▂▁▂▃▁▂▂▂▂▂</td></tr><tr><td>test_mse</td><td>█▄▃▃▃▂▂▁▂▂▁▁▂▁▁▁▂▂▁▁▁▂▁▂▂▁▂▂▂▁▂▁▂▂▁▂▂▂▂▂</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00919</td></tr><tr><td>test_mse</td><td>0.00013</td></tr><tr><td>train_mae</td><td>0.00859</td></tr><tr><td>train_mse</td><td>0.00012</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_thenlper_gte-base</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/2611fre7' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/2611fre7</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220002-2611fre7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   3%|▎         | 7/210 [01:47<50:58, 15.07s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220016-z5rpmam7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z5rpmam7' target=\"_blank\">WhereIsAI_UAE-Large-V1_thenlper_gte-large</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z5rpmam7' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z5rpmam7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3106.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3124.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3117.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3138.27it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3054.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3073.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2495.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3091.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3090.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3125.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3095.72it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3059.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3064.96it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.11it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3035.39it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3081.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3113.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3116.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3065.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3088.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3068.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3068.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3067.77it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3088.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3070.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3074.87it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3104.33it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3096.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3069.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3075.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3075.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3074.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.37it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3056.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3060.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.79it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3079.26it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3081.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.63it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mse</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.0049</td></tr><tr><td>test_mse</td><td>4e-05</td></tr><tr><td>train_mae</td><td>0.00457</td></tr><tr><td>train_mse</td><td>3e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_thenlper_gte-large</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z5rpmam7' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z5rpmam7</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220016-z5rpmam7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   4%|▍         | 8/210 [02:03<51:59, 15.44s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220033-z84nku7k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z84nku7k' target=\"_blank\">WhereIsAI_UAE-Large-V1_thenlper_gte-small</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z84nku7k' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z84nku7k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2943.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2994.77it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2959.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2943.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2969.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2982.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3012.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2933.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3045.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2998.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2820.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3008.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3008.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2933.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2975.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2848.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2945.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2978.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2955.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2956.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2962.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2969.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2952.31it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2994.80it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2947.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2969.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2809.77it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3011.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2992.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3004.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3018.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2876.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2998.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3002.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.77it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3017.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3019.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2975.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2990.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2988.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2986.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2987.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2953.35it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2977.61it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>test_mae</td><td>█▄▃▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▁▂▂▁▂▁▂▃▂▂▂</td></tr><tr><td>test_mse</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▁▂▂▁▂▁▂▃▂▁▂</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01268</td></tr><tr><td>test_mse</td><td>0.00025</td></tr><tr><td>train_mae</td><td>0.01177</td></tr><tr><td>train_mse</td><td>0.00022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_thenlper_gte-small</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z84nku7k' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/z84nku7k</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220033-z84nku7k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   4%|▍         | 9/210 [02:19<52:16, 15.61s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220049-iuag0ree</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/iuag0ree' target=\"_blank\">WhereIsAI_UAE-Large-V1_sentence-transformers_gtr-t5-base</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/iuag0ree' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/iuag0ree</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.27it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3117.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3098.01it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3094.38it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2560.49it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3099.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3119.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3140.15it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3111.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3125.05it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3164.83it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3127.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3137.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3094.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3134.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3109.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3014.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3139.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3127.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.39it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3166.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3110.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3152.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3058.31it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3120.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3110.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3129.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3145.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3194.83it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3168.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3168.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3193.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3122.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3139.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3140.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3193.54it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3179.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3193.26it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3186.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3166.47it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3194.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3168.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3119.47it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.74it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3184.91it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▂▁▁▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▂▂▃</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▂▁▁▂▂▂▂▁▂▂▁▂▂▂▂▂▂▁▂▂▃</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01309</td></tr><tr><td>test_mse</td><td>0.00027</td></tr><tr><td>train_mae</td><td>0.01211</td></tr><tr><td>train_mse</td><td>0.00023</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_sentence-transformers_gtr-t5-base</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/iuag0ree' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/iuag0ree</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220049-iuag0ree/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   5%|▍         | 10/210 [02:35<52:43, 15.82s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220105-uok5uco5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/uok5uco5' target=\"_blank\">WhereIsAI_UAE-Large-V1_sentence-transformers_gtr-t5-large</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/uok5uco5' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/uok5uco5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.27it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3137.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3071.37it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3156.43it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2975.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2982.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3109.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3120.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3123.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3129.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3094.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3108.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3118.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3103.31it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3144.39it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3127.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3126.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3110.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3083.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3121.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3105.87it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3132.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.20it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3105.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3142.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3142.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3120.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2979.57it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3121.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.49it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3089.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3130.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3130.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2443.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3045.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3027.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3042.34it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3045.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3051.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3028.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3091.16it/s]\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▄▃▃▂▂▂▂▁▁▂▂▁▂▂▁▁▂▁▂▁▂▁▁▂▁▁▂▁▂▁▁▁▁▁▂▂▁▂▂</td></tr><tr><td>test_mse</td><td>█▄▃▃▂▂▂▂▂▁▁▂▁▂▂▁▁▂▁▂▁▂▂▁▁▂▁▁▂▁▂▁▁▁▁▂▂▁▂▂</td></tr><tr><td>train_mae</td><td>█▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.01266</td></tr><tr><td>test_mse</td><td>0.00026</td></tr><tr><td>train_mae</td><td>0.01179</td></tr><tr><td>train_mse</td><td>0.00022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_sentence-transformers_gtr-t5-large</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/uok5uco5' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/uok5uco5</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220105-uok5uco5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   5%|▌         | 11/210 [02:52<53:13, 16.05s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220121-v5noqq1c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/v5noqq1c' target=\"_blank\">WhereIsAI_UAE-Large-V1_mixedbread-ai_mxbai-embed-large-v1</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/v5noqq1c' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/v5noqq1c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2892.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2862.14it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2878.84it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2905.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2919.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2940.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2916.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2932.26it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2893.76it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2344.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2965.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2953.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2921.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2893.82it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2950.23it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2950.89it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2912.80it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2956.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2936.10it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2895.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2948.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2913.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2936.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2985.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2962.26it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2896.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2922.83it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2957.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2935.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2959.09it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2960.97it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3059.56it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2903.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2921.55it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2914.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2915.29it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2946.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2950.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2926.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2804.51it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2910.95it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2930.39it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2923.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2976.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2870.06it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3079.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3082.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3067.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3063.48it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3084.95it/s]\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▆▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mse</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00189</td></tr><tr><td>test_mse</td><td>1e-05</td></tr><tr><td>train_mae</td><td>0.00186</td></tr><tr><td>train_mse</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_mixedbread-ai_mxbai-embed-large-v1</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/v5noqq1c' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/v5noqq1c</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220121-v5noqq1c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   6%|▌         | 12/210 [03:07<51:44, 15.68s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220136-mv1tgsmd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/mv1tgsmd' target=\"_blank\">WhereIsAI_UAE-Large-V1_sentence-transformers_sentence-t5-base</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/mv1tgsmd' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/mv1tgsmd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3028.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2973.72it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3020.93it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3045.44it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3044.36it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2984.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3054.50it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2970.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2993.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3016.62it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3005.59it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3007.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3029.32it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3029.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3001.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2989.28it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2985.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2974.68it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3032.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3035.52it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3043.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3034.98it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3033.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3007.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2993.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3034.29it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3044.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2948.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2980.18it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2995.81it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3032.10it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3033.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3024.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2934.99it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3034.01it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3023.11it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3044.05it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2994.04it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3047.24it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3022.64it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3027.13it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3033.42it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3025.91it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3039.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2964.02it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3024.07it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3036.84it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2995.17it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3046.92it/s]\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_mae</td><td>█▅▄▃▂▁▃▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▂▂▂▂▂▂▁▂▂▂▃▂▂▃▂▂▂▂</td></tr><tr><td>test_mse</td><td>█▅▄▃▂▃▂▂▂▁▂▂▁▁▁▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_mae</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mse</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>test_mae</td><td>0.00816</td></tr><tr><td>test_mse</td><td>0.00011</td></tr><tr><td>train_mae</td><td>0.00767</td></tr><tr><td>train_mse</td><td>9e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WhereIsAI_UAE-Large-V1_sentence-transformers_sentence-t5-base</strong> at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/mv1tgsmd' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/mv1tgsmd</a><br/> View project at: <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241210_220136-mv1tgsmd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training transforms (all default settings):   6%|▌         | 13/210 [03:23<52:41, 16.05s/it]/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/align3_drive/adrianoh/git/embedding_translation/owler_fork/owlergpt/commands/wandb/run-20241210_220153-k0hi8bvf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/k0hi8bvf' target=\"_blank\">WhereIsAI_UAE-Large-V1_sentence-transformers_sentence-t5-large</a></strong> to <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/k0hi8bvf' target=\"_blank\">https://wandb.ai/4gate/2024_12_09_dl_project_layer_train/runs/k0hi8bvf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3151.61it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3100.00it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3123.12it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3097.16it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2973.69it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3024.92it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2907.58it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3086.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3058.63it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3076.71it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2871.46it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3024.67it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3044.90it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2843.73it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3062.21it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2914.45it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3092.40it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2925.22it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3107.35it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3135.66it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3061.70it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3136.03it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3146.41it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3130.85it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3138.01it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3105.94it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2953.53it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3093.60it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3080.75it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3103.08it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3138.78it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2915.37it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3001.01it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3084.86it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2948.25it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 2897.30it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3138.88it/s]\n",
      "\n",
      "100%|██████████| 70/70 [00:00<00:00, 3114.67it/s]\n",
      " 76%|███████▌  | 38/50 [00:10<00:03,  3.50it/s]\n",
      "/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2368: UserWarning: Run (4zvzgqqg) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "Training transforms (all default settings):   6%|▌         | 13/210 [03:36<54:35, 16.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m EmbeddingTransformTrainer(\n\u001b[1;32m      2\u001b[0m     save_path_parent\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/align3_drive/adrianoh/dl_final_project_layers/arguana_hf_cartesian_product\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m     load_path_parent\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/align3_drive/adrianoh/dl_final_project_embeddings_huggingface\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_all_pairs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_against_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalesforce/SFR-Embedding-Mistral\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-3-large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-embedding-3-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_for_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marguana\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 136\u001b[0m, in \u001b[0;36mEmbeddingTransformTrainer.train_all_pairs\u001b[0;34m(self, filter_against_model, filter_for_model, filter_for_dataset, filter_against_dataset)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    126\u001b[0m trainer \u001b[38;5;241m=\u001b[39m LinearTransformTrainer(\n\u001b[1;32m    127\u001b[0m     save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[1;32m    128\u001b[0m     linear\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     args\u001b[38;5;241m=\u001b[39mDEFAULT_ARGS\n\u001b[1;32m    135\u001b[0m )\n\u001b[0;32m--> 136\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[26], line 113\u001b[0m, in \u001b[0;36mLinearTransformTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(source_emb)\n\u001b[1;32m    112\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss(output, target_emb)\n\u001b[0;32m--> 113\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    116\u001b[0m train_mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/align3_drive/adrianoh/miniconda3/envs/python311/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = EmbeddingTransformTrainer(\n",
    "    save_path_parent=Path(\"/mnt/align3_drive/adrianoh/dl_final_project_layers/arguana_hf_cartesian_product\"),\n",
    "    load_path_parent=Path(\"/mnt/align3_drive/adrianoh/dl_final_project_embeddings_huggingface\"),\n",
    "    device=\"cuda:0\",\n",
    "    wandb_project=\"2024_12_11_dl_project_layer_arguana_hf_only_train\"\n",
    ")\n",
    "trainer.train_all_pairs(\n",
    "    filter_against_model=[\"Salesforce/SFR-Embedding-Mistral\",\"text-embedding-3-large\",\"text-embedding-3-small\"],\n",
    "    filter_for_dataset=[\"arguana\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
