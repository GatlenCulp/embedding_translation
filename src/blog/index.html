<!doctype html>
<meta charset="utf-8" />
<head>
  <title>
    LEAD: Linear Embedding Alignment across Deep Neural Network Language Models'
    Representations
  </title>
  <script src="https://distill.pub/template.v1.js"></script>
  <link
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"
    rel="stylesheet" />
  <link
    href="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.css"
    rel="stylesheet"
    integrity="sha384-Htz9HMhiwV8GuQ28Xr9pEs1B4qJiYu/nYLLwlDklR53QibDfmQzi7rYxXhMH/5/u"
    crossorigin="anonymous" />
  <link href="styles.css" rel="stylesheet" />

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script
    src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.js"
    defer
    integrity="sha384-bxmi2jLGCvnsEqMuYLKE/KsVCxV3PqmKeK6Y6+lmNXBry6+luFkEOsmp5vD9I/7+"
    crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script
    src="https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/contrib/auto-render.min.js"
    defer
    integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh"
    crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js"></script>
  <script>
    mermaid.initialize({ startOnLoad: true });
  </script>
  <!-- prettier-ignore -->
  <script type="text/bibliography">
    @inproceedings{andrew_deep_2013,
      title     = {Deep {Canonical} {Correlation} {Analysis}},
      url       = {https://proceedings.mlr.press/v28/andrew13.html},
      abstract  = {We introduce Deep Canonical Correlation Analysis (DCCA), a method to learn complex nonlinear transformations of two views of data such that the resulting representations are highly linearly correlated...},
      language  = {en},
      urldate   = {2024-11-15},
      booktitle = {Proceedings of the 30th {International} {Conference} on {Machine} {Learning}},
      publisher = {PMLR},
      author    = {Andrew, Galen and Arora, Raman and Bilmes, Jeff and Livescu, Karen},
      month     = may,
      year      = {2013},
      note      = {ISSN: 1938-7228},
      pages     = {1247--1255}
    }
    
    @misc{andriushchenko_jailbreaking_2024,
      title     = {Jailbreaking {Leading} {Safety}-{Aligned} {LLMs} with {Simple} {Adaptive} {Attacks}},
      url       = {http://arxiv.org/abs/2404.02151},
      doi       = {10.48550/arXiv.2404.02151},
      abstract  = {We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks...},
      urldate   = {2024-11-15},
      publisher = {arXiv},
      author    = {Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas},
      month     = oct,
      year      = {2024},
      note      = {arXiv:2404.02151},
      keywords  = {Computer Science - Machine Learning, AI, Security}
    }
    
    @article{anthropic,
      title    = {Towards {Monosemanticity}: {Decomposing} {Language} {Models} {With} {Dictionary} {Learning}},
      author   = {Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nicholas L. and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E. and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Chris},
      url      = {https://www.anthropic.com/research/towards-monosemanticity-decomposing-language-models-with-dictionary-learning},
      abstract = {Anthropic is an AI safety and research company...},
      language = {en},
      urldate  = {2024-11-15},
      year     = {2023}
    }

@inproceedings{bansal_revisiting_2021,
  title     = {Revisiting {Model} {Stitching} to {Compare} {Neural} {Representations}},
  volume    = {34},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/01ded4259d101feb739b06c399e9cd9c-Abstract.html},
  urldate   = {2024-11-15},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  publisher = {Curran Associates, Inc.},
  author    = {Bansal, Yamini and Nakkiran, Preetum and Barak, Boaz},
  year      = {2021},
  pages     = {225--236}
}


@article{cammarata_curve_2020,
  title    = {Curve {Detectors}},
  volume   = {5},
  issn     = {2476-0757},
  url      = {https://distill.pub/2020/circuits/curve-detectors},
  doi      = {10.23915/distill.00024.003},
  abstract = {Part one of a three part deep dive into the curve neuron family.},
  language = {en},
  number   = {6},
  urldate  = {2024-11-15},
  journal  = {Distill},
  author   = {Cammarata, Nick and Goh, Gabriel and Carter, Shan and Schubert, Ludwig and Petrov, Michael and Olah, Chris},
  month    = jun,
  year     = {2020},
  pages    = {e00024.003}
}

[COMMENTED] Missing required journal and volume/number fields
@misc{caspari2024benchmarksevaluatingembeddingmodel,
  title         = {Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems},
  author        = {Laura Caspari and Kanishka Ghosh Dastidar and Saber Zerhoudi and Jelena Mitrovic and Michael Granitzer},
  year          = {2024},
  eprint        = {2407.08275},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2407.08275}
}

@misc{chao_jailbreaking_2024,
  title     = {Jailbreaking {Black} {Box} {Large} {Language} {Models} in {Twenty} {Queries}},
  url       = {http://arxiv.org/abs/2310.08419},
  doi       = {10.48550/arXiv.2310.08419},
  abstract  = {We propose Prompt Automatic Iterative Refinement (PAIR), a method that generates semantic jailbreaks with only black-box access...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J. and Wong, Eric},
  month     = jul,
  year      = {2024},
  note      = {arXiv:2310.08419}
}

@misc{cunningham_sparse_2023,
  title     = {Sparse {Autoencoders} {Find} {Highly} {Interpretable} {Features} in {Language} {Models}},
  url       = {http://arxiv.org/abs/2309.08600},
  doi       = {10.48550/arXiv.2309.08600},
  abstract  = {We show that sparse autoencoders can resolve superposition in language models...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  month     = oct,
  year      = {2023},
  note      = {arXiv:2309.08600}
}

@inproceedings{eberle-etal-2022-transformer,
  title     = {Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?},
  author    = {Eberle, Oliver and Brandl, Stephanie and Pilot, Jonas and S{\o}gaard, Anders},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-long.296},
  doi       = {10.18653/v1/2022.acl-long.296},
  pages     = {4295--4309}
}

@article{haxby_decoding_2014,
  title    = {Decoding {Neural} {Representational} {Spaces} {Using} {Multivariate} {Pattern} {Analysis}},
  volume   = {37},
  issn     = {0147-006X, 1545-4126},
  url      = {https://www.annualreviews.org/doi/10.1146/annurev-neuro-062012-170325},
  doi      = {10.1146/annurev-neuro-062012-170325},
  abstract = {A review discussing methods for decoding human neural activity...},
  language = {en},
  number   = {1},
  urldate  = {2024-11-15},
  journal  = {Annual Review of Neuroscience},
  author   = {Haxby, James V. and Connolly, Andrew C. and Guntupalli, J. Swaroop},
  month    = jul,
  year     = {2014},
  pages    = {435--456}
}

@misc{hernandez_model_2023,
  title     = {Model {Stitching}: {Looking} {For} {Functional} {Similarity} {Between} {Representations}},
  url       = {http://arxiv.org/abs/2303.11277},
  doi       = {10.48550/arXiv.2303.11277},
  abstract  = {Model stitching is a methodology to compare neural network representations by measuring their interchangeability...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Hernandez, Adriano and Dangovski, Rumen and Lu, Peter Y. and Soljacic, Marin},
  month     = aug,
  year      = {2023},
  note      = {arXiv:2303.11277}
}

@misc{huh_platonic_2024,
  title     = {The {Platonic} {Representation} {Hypothesis}},
  url       = {http://arxiv.org/abs/2405.07987},
  doi       = {10.48550/arXiv.2405.07987},
  abstract  = {We argue that representations in AI models are converging, driving toward a shared statistical model of reality...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
  month     = jul,
  year      = {2024},
  note      = {arXiv:2405.07987}
}
@article{klabunde_similarity_2023,
  title    = {Similarity of {Neural} {Network} {Models}: {A} {Survey} of {Functional} and {Representational} {Measures}},
  url      = {https://arxiv.org/abs/2305.06329},
  doi      = {10.48550/ARXIV.2305.06329},
  abstract = {A survey of measures for functional and representational similarity in neural networks...},
  urldate  = {2024-11-15},
  author   = {Klabunde, Max and Schumacher, Tobias and Strohmaier, Markus and Lemmerich, Florian},
  year     = {2023}
}@article{Klabunde2023TowardsMR,
  title   = {Towards Measuring Representational Similarity of Large Language Models},
  author  = {Klabunde, Max and Ben Amor, Mehdi and Granitzer, Michael and Lemmerich, Florian},
  journal = {ArXiv},
  year    = {2023},
  volume  = {abs/2312.02730},
  url     = {https://arxiv.org/abs/2312.02730}
}

@misc{kornblith_similarity_2019,
  title     = {Similarity of {Neural} {Network} {Representations} {Revisited}},
  url       = {http://arxiv.org/abs/1905.00414},
  doi       = {10.48550/arXiv.1905.00414},
  abstract  = {Examines methods for comparing neural network representations based on CCA and introduces CKA...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  month     = jul,
  year      = {2019},
  keywords  = {Machine Learning}
}
@article{kriegeskorte_representational_2008,
  title    = {Representational similarity analysis - connecting the branches of systems neuroscience},
  volume   = {2},
  issn     = {1662-5137},
  url      = {https://www.frontiersin.org/articles/10.3389/neuro.06.004.2008/full},
  doi      = {10.3389/neuro.06.004.2008},
  abstract = {A framework to quantitatively relate brain-activity measurement, behavior, and computational modeling via RSA...},
  language = {en},
  urldate  = {2024-11-15},
  journal  = {Frontiers in Systems Neuroscience},
  author   = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter A.},
  month    = nov,
  year     = {2008}
}
@misc{lenc2015understandingimagerepresentationsmeasuring,
  title         = {Understanding image representations by measuring their equivariance and equivalence},
  author        = {Karel Lenc and Andrea Vedaldi},
  year          = {2015},
  eprint        = {1411.5908},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1411.5908}
}
@misc{li2016convergentlearningdifferentneural,
  title         = {Convergent Learning: Do different neural networks learn the same representations?},
  author        = {Li, Yixuan and Yosinski, Jason and Clune, Jeff and Lipson, Hod and Hopcroft, John},
  year          = {2016},
  eprint        = {1511.07543},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1511.07543}
}

@misc{mehrotra_tree_2024,
  title     = {Tree of {Attacks}: {Jailbreaking} {Black}-{Box} {LLMs} {Automatically}},
  url       = {http://arxiv.org/abs/2312.02119},
  doi       = {10.48550/arXiv.2312.02119},
  abstract  = {We present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that requires only black-box access...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  month     = oct,
  year      = {2024},
  note      = {arXiv:2312.02119}
}
@misc{michaud2024quantizationmodelneuralscaling,
  title         = {The Quantization Model of Neural Scaling},
  author        = {Eric J. Michaud and Ziming Liu and Uzay Girit and Max Tegmark},
  year          = {2024},
  eprint        = {2303.13506},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2303.13506}
}
@inproceedings{morcos_insights_2018,
  title    = {Insights on representational similarity in neural networks with canonical correlation},
  abstract = {Uses projection weighted CCA to study representational similarity across CNNs and RNNs...},
  urldate  = {2024-11-15},
  author   = {Morcos, Ari S. and Raghu, Maithra and Bengio, Samy},
  month    = jun,
  year     = {2018}
}
@misc{muennighoff2023mtebmassivetextembedding,
  title         = {MTEB: Massive Text Embedding Benchmark},
  author        = {Niklas Muennighoff and Nouamane Tazi and Loïc Magne and Nils Reimers},
  year          = {2023},
  eprint        = {2210.07316},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.07316}
}
@misc{nguyen_wide_2021,
  title     = {Do {Wide} and {Deep} {Networks} {Learn} the {Same} {Things}? {Uncovering} {How} {Neural} {Network} {Representations} {Vary} with {Width} and {Depth}},
  url       = {http://arxiv.org/abs/2010.15327},
  doi       = {10.48550/arXiv.2010.15327},
  abstract  = {Investigates how varying depth and width affects model hidden representations...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Nguyen, Thao and Raghu, Maithra and Kornblith, Simon},
  month     = apr,
  year      = {2021},
  keywords  = {Computer Science - Machine Learning}
}
@misc{noauthor_20_scaling_lawspdf_nodate,
  title    = {20\_scaling\_laws.pdf},
  url      = {https://www.dropbox.com/scl/fi/xhnv84zx78u0l8o1o4pce/20_scaling_laws.pdf?dl=0&e=1&rlkey=ucg32vqlxgadea3enzh90qaop},
  abstract = {Shared with Dropbox},
  language = {en},
  urldate  = {2024-11-15}
}
@misc{noauthor_mantis_nodate,
  title   = {Mantis},
  url     = {https://home.withmantis.com/},
  urldate = {2024-11-15}
}
@misc{noauthor_model_nodate,
  title    = {Model {Stitching}: {Looking} {For} {Functional} {Similarity} {Between} {Representations}},
  url      = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evT71z8AAAAJ&citation_for_view=evT71z8AAAAJ:u5HHmVD_uO8C},
  abstract = {Short summary referencing model stitching and functional similarity.},
  urldate  = {2024-11-15}
}
@misc{noauthor_simon_nodate,
  title    = {Simon {Kornblith} - {AI} + {Science} {Talk} {Part} 1\&2.pdf | Powered by Box},
  url      = {https://uchicago.app.box.com/s/ymyt6ushjg94l1aauutgwq256w30mhbg},
  language = {en-US},
  urldate  = {2024-11-15}
}
@article{olah2020zoom,
  author  = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
  title   = {Zoom In: An Introduction to Circuits},
  journal = {Distill},
  year    = {2020},
  note    = {https://distill.pub/2020/circuits/zoom-in},
  doi     = {10.23915/distill.00024.001}
}
@article{olsson2022context,
  title   = {In-context Learning and Induction Heads},
  author  = {Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
  year    = {2022},
  journal = {Transformer Circuits Thread},
  note    = {https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}
@misc{park2024linearrepresentationhypothesisgeometry,
  title         = {The Linear Representation Hypothesis and the Geometry of Large Language Models},
  author        = {Kiho Park and Yo Joong Choe and Victor Veitch},
  year          = {2024},
  eprint        = {2311.03658},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2311.03658}
}
@misc{pliny_elder-pliniusl1b3rt4s_2024,
  title    = {elder-plinius/{L1B3RT4S}},
  url      = {https://github.com/elder-plinius/L1B3RT4S},
  abstract = {TOTALLY HARMLESS LIBERATION PROMPTS FOR GOOD LIL AI'S},
  urldate  = {2024-11-15},
  author   = {pliny},
  month    = nov,
  year     = {2024}
}
@misc{radford_learning_2021,
  title     = {Learning {Transferable} {Visual} {Models} {From} {Natural} {Language} {Supervision}},
  url       = {http://arxiv.org/abs/2103.00020},
  doi       = {10.48550/arXiv.2103.00020},
  abstract  = {Introduces CLIP, trained on (image, text) pairs to learn visual representations...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  month     = feb,
  year      = {2021},
  keywords  = {Computer Vision, Representation Learning}
}
@misc{sahlgren2021sentenceembeddingsensembledistillation,
  title         = {Sentence Embeddings by Ensemble Distillation},
  author        = {Fredrik Carlsson Magnus Sahlgren},
  year          = {2021},
  eprint        = {2104.06719},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2104.06719}
}
@article{schubert2021high-low,
  author  = {Schubert, Ludwig and Voss, Chelsea and Cammarata, Nick and Goh, Gabriel and Olah, Chris},
  title   = {High-Low Frequency Detectors},
  journal = {Distill},
  year    = {2021},
  note    = {https://distill.pub/2020/circuits/frequency-edges},
  doi     = {10.23915/distill.00024.005}
}
@misc{song2024resourcemodelneuralscaling,
  title         = {A Resource Model For Neural Scaling Law},
  author        = {Jinyeop Song and Ziming Liu and Max Tegmark and Jeff Gore},
  year          = {2024},
  eprint        = {2402.05164},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.05164}
}
@misc{sucholutsky2024gettingalignedrepresentationalalignment,
  title         = {Getting aligned on representational alignment},
  author        = {Ilia Sucholutsky and Lukas Muttenthaler and Adrian Weller and Andi Peng and Andreea Bobu and Been Kim and Bradley C. Love and Christopher J. Cueva and Erin Grant and Iris Groen and Jascha Achterberg and Joshua B. Tenenbaum and Katherine M. Collins and Katherine L. Hermann and Kerem Oktar and Klaus Greff and Martin N. Hebart and Nathan Cloos and Nikolaus Kriegeskorte and Nori Jacoby and Qiuyi Zhang and Raja Marjieh and Robert Geirhos and Sherol Chen and Simon Kornblith and Sunayana Rane and Talia Konkle and Thomas P. O'Connell and Thomas Unterthiner and Andrew K. Lampinen and Klaus-Robert Müller and Mariya Toneva and Thomas L. Griffiths},
  year          = {2024},
  eprint        = {2310.13018},
  archiveprefix = {arXiv},
  primaryclass  = {q-bio.NC},
  url           = {https://arxiv.org/abs/2310.13018}
}
@misc{ling2021nearoptimalboundsgeneralizedorthogonal,
  title={Near-Optimal Bounds for Generalized Orthogonal Procrustes Problem via Generalized Power Method}, 
  author={Shuyang Ling},
  year={2021},
  eprint={2112.13725},
  archivePrefix={arXiv},
  primaryClass={cs.IT},
  url={https://arxiv.org/abs/2112.13725}, 
}

@article{yousefnezhad_deep_2021,
  title    = {Deep {Representational} {Similarity} {Learning} for {Analyzing} {Neural} {Signatures} in {Task}-based {fMRI} {Dataset}},
  volume   = {19},
  issn     = {1539-2791, 1559-0089},
  url      = {https://link.springer.com/10.1007/s12021-020-09494-4},
  doi      = {10.1007/s12021-020-09494-4},
  abstract = {Introduces DRSL, a deep extension of RSA suitable for analyzing similarities between cognitive tasks in large fMRI datasets...},
  language = {en},
  number   = {3},
  urldate  = {2024-11-15},
  journal  = {Neuroinformatics},
  author   = {Yousefnezhad, Muhammad and Sawalha, Jeffrey and Selvitella, Alessandro and Zhang, Daoqiang},
  month    = jul,
  year     = {2021},
  pages    = {417--431}
}
@misc{zhou_object_2015,
  title     = {Object {Detectors} {Emerge} in {Deep} {Scene} {CNNs}},
  url       = {http://arxiv.org/abs/1412.6856},
  doi       = {10.48550/arXiv.1412.6856},
  abstract  = {Demonstrates that object detectors emerge as a byproduct of training CNNs for scene classification...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  month     = apr,
  year      = {2015}
}
@misc{zou_universal_2023,
  title     = {Universal and {Transferable} {Adversarial} {Attacks} on {Aligned} {Language} {Models}},
  url       = {http://arxiv.org/abs/2307.15043},
  doi       = {10.48550/arXiv.2307.15043},
  abstract  = {Proposes an approach to automatically produce adversarial suffixes for LLMs, achieving attacks that transfer to many models...},
  urldate   = {2024-11-15},
  publisher = {arXiv},
  author    = {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J. Zico and Fredrikson, Matt},
  month     = dec,
  year      = {2023}
}
@misc{bansal2021revisitingmodelstitchingcompare,
  title={Revisiting Model Stitching to Compare Neural Representations}, 
  author={Yamini Bansal and Preetum Nakkiran and Boaz Barak},
  year={2021},
  eprint={2106.07682},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2106.07682}, 
}
  </script>

  <script type="text/front-matter">
    title: "LEAD: Linear Embedding Alignment across Deep Neural Network Language Models' Representations"
    description: "Exploring whether different LLM-based semantic-search embedding models learn similar representations to push forward our understanding of LLM representations and lower the barrier to entry for semantic search and visualization."
    authors:
    - Gatlen Culp: https://gatlen.notion.site
    - Adriano Hernandez: https://linktr.ee/4gate
    affiliations:
    - MIT: http://web.mit.edu/
    - MIT: http://web.mit.edu/
  </script>
</head>

<body>
  <dt-article class="centered">
    <div class="l-middle">
      <figure>
        <img
          src="./header.png"
          alt="Header visualization of semantic alignment across language models"
          style="width: 100%; max-height: 400px; object-fit: cover" />
      </figure>
    </div>
    <h1 id="title">
      LEAD: Linear Embedding Alignment across Deep Neural Network Language
      Models' Representations
    </h1>

    <!-- <dt-byline></dt-byline> -->

    <div
      class="authors-section l-middle"
      style="text-align: center; margin-top: 2em">
      <div class="authors" style="margin-bottom: 1em">
        <span style="font-size: 1.2em">
          <a
            href="https://gatlen.notion.site"
            style="text-decoration: none; color: #333"
            >Gatlen Culp</a
          ><sup>*</sup>
          <span style="color: #666; margin: 0 0.5em">·</span>
          <a
            href="https://superurop.mit.edu/scholars/adriano-hernandez/"
            style="text-decoration: none; color: #333"
            >Adriano Hernandez</a
          ><sup>*</sup>
        </span>
      </div>

      <div class="affiliations" style="color: #666; margin-bottom: 1em">
        Massachusetts Institute of Technology
      </div>

      <div class="date-info" style="color: #888; font-size: 0.9em">
        Published December 10th, 2024
        <br />
        <span style="font-size: 0.9em">* Equal contribution</span>
      </div>
    </div>
    <!-- TODO: we MUST add some sort of control i.e. via random projections -->
    <h2 id="abstract">Abstract</h2>
    <p>
      Recent advances in Large Language Models (LLMs) have demonstrated their
      remarkable ability to capture semantic information. We investigate whether
      different language embedding models learn similar semantic representations
      despite variations in architecture, training data, and initialization.
      While previous work explored model similarity through top-k results and
      Centered Kernel Alignment (CKA), yielding mixed results, we introduce a
      linear connectivity analysis approach: training linear mappings between
      embedding spaces. We define two spaces as connectivity-aligned if these
      mappings achieve low mean squared error, indicating approximate
      bijectivity.
    </p>
    <p>
      Our analysis spans 6 embedding datasets (5,000-20,000 documents) and 18
      models (between 20-30 layers, including both open-source and OpenAI
      models). Results demonstrate significant connectivity-alignment between
      most models' semantic spaces, with notable exceptions. These findings
      support both the Linear Representation Hypothesis and, more tentatively,
      the Platonic Representation Hypothesis. Practically, our approach could
      reduce the cost of merging embedding datasets by a factor of 20 or more.
      Our datasets, code, and results are publicly available on GitHub and
      Hugging Face.
    </p>

    <h2 id="introduction">00 Introduction & Terminology</h2>
    <p>
      Modern language models convert text into dense vectors called embeddings,
      which capture semantic meaning in a high-dimensional space. We investigate
      whether different models learn similar semantic representations despite
      variations in architecture, training data, and initialization. If these
      representations are indeed (approximately) universal, we could leverage
      this to efficiently translate between different models' embeddings.
    </p>

    <p>
      The paper
      <i>
        Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval
        Augmented Generation Systems
      </i>
      <dt-cite key="caspari2024benchmarksevaluatingembeddingmodel"></dt-cite>
      explored embedding model representational similarity through techniques
      like top-k search retrieval results and Centered Kernel Alignment (CKA).
      We take their methodology expand upon it here by systematically studying
      whether there exists a method to cheaply determine and translate between
      embeddings of models with similar characteristics. Our approach reveals
      whether models learn similar semantic features that can be recovered
      through linear transformations, even if those features are encoded
      differently across models.
    </p>

    <div class="l-page side">
      <div class="l-page">
        <figure class="diagram-container">
          <!-- prettier-ignore -->
          <div class="mermaid">
          graph TD
            %% Define the main text input with proper quotes
            Text[/"Input Text t"/]

            %% Define embedding spaces as subgraphs with proper syntax
            subgraph SpaceA["Embedding Space A"]
                NativeA["Native Embedding A(t)"]
            end

            subgraph SpaceB["Embedding Space B"]
                NativeB["Native Embedding B(t)"]
                StitchedAB["Stitched Embedding S(A(t))"]
            end

            %% Define the models and transformations
            ModelA["Model A"]
            ModelB["Model B"]
            Stitch{{"Stitch S"}}

            %% Define the relationships with proper flow
            Text --> ModelA
            Text --> ModelB
            ModelA --> NativeA
            ModelB --> NativeB
            NativeA --> Stitch
            Stitch --> StitchedAB

            %% Add evaluation with proper syntax
            MSE[["MSE(S(A(t)), B(t) < ε"]]
            StitchedAB -.-> MSE
            NativeB -.-> MSE

            %% Style definitions
            classDef space fill:#f0f4f8,stroke:#a3bffa,rx:10
            classDef model fill:#ebf4ff,stroke:#63b3ed,rx:5
            classDef stitch fill:#faf5ff,stroke:#b794f4,rx:5
            classDef evaluation fill:#f0fff4,stroke:#68d391,rx:5

            %% Apply styles
            class SpaceA,SpaceB space
            class ModelA,ModelB model
            class Stitch stitch
            class MSE evaluation
        </div>
          <figcaption>
            Relationship between native embeddings, stitched embeddings, and
            embedding spaces.
          </figcaption>
        </figure>
      </div>
    </div>

    <p>We define key terminology and notation used throughout this paper:</p>

    <ul style="list-style: none; padding-left: 0">
      <li style="margin-bottom: 1em">
        <b>Embedding Space:</b> The set of all possible embeddings produced by a
        specific model, along with their feature composition, and relationships
        to one another. For a model \(M\), we denote its embedding space as
        \(\mathcal{E}_M \subset \mathbb{R}^d\), where \(d\) is the embedding
        dimension. While mathematically these may share the same dimension
        (e.g., \(d=1024\)), each model's unique mapping creates a distinct
        semantic space. (\(d=1024\)), each model's unique mapping creates a
        distinct semantic space.
        <!-- why isn't this rendering -->
        <dt-fn>
          This is not a formal or rigorous definition, rather a useful concept
          to name.
        </dt-fn>
        <!-- subseteq not working -->
      </li>

      <li style="margin-bottom: 1em">
        <b>Stitch:</b> Following previous literature
        <dt-cite
          key="lenc2015understandingimagerepresentationsmeasuring"></dt-cite>
        , we call a linear transformation between two embedding spaces a
        "stitch". For models \(A\) and \(B\), a stitch \(S_{A\rightarrow B}:
        \mathcal{E}_A \rightarrow \mathcal{E}_B\) is a linear map that attempts
        to preserve semantic relationships.
        <dt-fn>
          Throughout this blog post, we use the terms linear and affine
          identically, much to the chagrin of mathematicians.
        </dt-fn>
      </li>
      <!-- Wait am I dumb, why did we use affine specifically and NOT linear? With Linear we
     could easily compose new translations by just doing the matrix multiplication. -->

      <li style="margin-bottom: 1em">
        <b>Connectivity-Alignment:</b> We say two embedding spaces
        \(\mathcal{E}_A\) and \(\mathcal{E}_B\) are connectivity-aligned if
        there exists a stitch \(S_{A\rightarrow B}\) that achieves low mean
        squared error: \[\text{MSE}(S_{A\rightarrow B}) =
        \frac{1}{n}\sum_{i=1}^n \|S_{A\rightarrow B}(x_i) - y_i\|^2 < \epsilon\]
        where \(x_i \in \mathcal{E}_A\), \(y_i \in \mathcal{E}_B\) are
        corresponding embeddings, and \(\epsilon\) is a threshold. This
        indicates the spaces preserve similar semantic features, albeit
        potentially encoded differently.
        <dt-fn
          >This is perhaps analagous to (approximate) isomorphism for vector
          spaces.</dt-fn
        >
      </li>

      <li style="margin-bottom: 1em">
        <b>Native vs. Stitched Embeddings:</b> For a text input \(t\) and model
        \(M\), we denote its native embedding as \(M(t) \in \mathcal{E}_M\).
        When we map embeddings from model \(A\) to model \(B\)'s space using a
        stitch, we denote the stitched embedding as \(S_{A\rightarrow B}(A(t))
        \in \mathcal{E}_B\).
      </li>
    </ul>

    <p>
      Our key hypothesis is that embedding models of similar scale (parameters,
      training data size, etc.) are connectivity-aligned. The results confirm
      this is a common phenomenon across many widely-used models, though some
      interesting exceptions exist.
      <!-- Are there exceptions we found? delete/change otherwise -->
      This finding has both theoretical implications for understanding how
      language models represent meaning and practical applications for efficient
      embedding translation.
    </p>

    <h2 id="motivation">01 Motivation</h2>

    <p>
      Imagine you've just spent weeks processing millions of documents through a
      language model to create semantic search capabilities. Then, a more
      powerful model is released – but recomputing all those embeddings would
      cost thousands of dollars and days of processing time. What if there was a
      better way?
    </p>

    <div class="l-page side">
      <figure>
        <img src="./figs/mantis.gif" alt="Exploring a dataset with MantisAI" />
        <figcaption>
          Exploring semantic relationships in data with MantisAI's visualization
          tools
        </figcaption>
      </figure>
    </div>

    <h3 id="origin">The Origin Story</h3>
    <p>
      This research emerged from real-world challenges at
      <a href="https://home.withmantis.com/">MantisAI</a>, where we help
      organizations understand and visualize large document collections. Our
      customers frequently needed to switch between different embedding models –
      sometimes prioritizing accuracy, other times speed or cost. But each
      switch required reprocessing entire datasets, creating significant
      computational overhead and compatibility challenges between workspaces.
    </p>

    <ul style="list-style: none; padding-left: 0">
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-flask"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Theoretical Foundations:</b> Our work investigates two fundamental
          hypotheses about how neural networks understand language. The
          <a href="https://phillipi.github.io/prh/"
            >Platonic Representation Hypothesis</a
          >
          suggests that models naturally converge toward similar ways of
          representing meaning, even when trained differently. The Linear
          Representation Hypothesis proposes these representations are linearly
          decomposable, allowing simple transformations between models.
        </div>
      </li>

      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-rocket"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Practical Impact:</b> The implications are significant:
          organizations could reduce computational costs by up to 95% using
          lightweight translation layers instead of recomputing embeddings with
          only a small cost in quality. Since these linear layers are
          approximately 1/20th the size of full embedding models, tasks like
          merging visualization datasets become dramatically more efficient.
          This efficiency extends beyond cost savings to environmental impact,
          making AI systems more sustainable. This interoperability could
          encourage dataset producers to publish their text embeddings alongside
          the data itself to bootstrap fast and inexpensive training and even
          mix-and-matching decoders or distillations that have been trained on
          the embeddings produced by another model. While not directly explored
          in our research, this methodology could be helpful in identifying
          dissimilar representations in models for better knowledge distillation
          <dt-cite
            key="sahlgren2021sentenceembeddingsensembledistillation"></dt-cite>
          or potentially for interpretabiltiy or data attribution
        </div>
      </li>

      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-microscope"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Research Questions:</b> We explore three interconnected questions:
          First, are embedding models linearly connectivity-aligned? Second,
          what is the minimal complexity needed for effective translation
          between embedding spaces? Finally, which types of models share more
          similar representations? Understanding these relationships could
          revolutionize how we deploy and scale AI systems.
        </div>
      </li>
    </ul>

    <h3>Looking Forward</h3>
    <p>
      Beyond immediate applications in cost reduction and efficiency, this
      research opens new possibilities for AI development. Understanding how
      different models encode similar information could lead to more efficient
      training procedures, better model architectures, and eventually,
      standardized intermediate embedding spaces that facilitate easier
      interoperability between AI systems.
    </p>

    <h2 id="relevant-work">02 Relevant Work</h2>

    <p>
      There is ample evidence supporting the idea that neural network
      representations may be aligned to some degree. Some notable observations
      include:
    </p>
    <div class="l-page side">
      <figure>
        <img
          src="./figs/platonic_rep.jpg"
          alt="Exploring a dataset with MantisAI" />
        <figcaption>
          Diagram illustrating the platonic representaton hypothesis
        </figcaption>
      </figure>
    </div>
    <ul style="list-style: none; padding-left: 0">
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-chart-line"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Scaling Laws and Platonic Representations:</b> recent work has
          provided strong evidence that many different neural network models,
          even those trained on different datasets, or different sensory
          modalities, converge to a shared representation of the world
          <dt-cite key="huh_platonic_2024"></dt-cite>. Scaling laws based on
          quantized models of learning
          <dt-cite key="michaud2024quantizationmodelneuralscaling"></dt-cite>
          <dt-cite key="song2024resourcemodelneuralscaling"></dt-cite> also
          suggest at a compelling world-view in which different models, despite
          differing in architecture, training data, or training methodology,
          converge to shared representations of the world.
        </div>
      </li>
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-network-wired"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Functionally similar components across neural networks:</b> For
          instance, induction heads have been observed in different language
          transformer architectures <dt-cite key="olsson2022context"></dt-cite>.
          Similar patterns have also been found in vision models
          <dt-cite key="cammarata_curve_2020"></dt-cite>
          <dt-cite key="schubert2021high-low"></dt-cite>
          <dt-cite key="olah2020zoom"></dt-cite>. We believe that such
          functionally similar components correspond to similar internal
          representations, and the language setting is relatively less explored.
        </div>
      </li>
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-brain"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Consistent representations and behaviors:</b> Previous work has
          shown that different transformers exhibit consistent attention
          patterns for similar semantic concepts
          <dt-cite key="eberle-etal-2022-transformer"></dt-cite>, often aligning
          with human judgments. In vision, linear mappings can translate between
          representation spaces of different models, enabling interoperability
          <dt-cite key="hernandez_model_2023"></dt-cite>
          <dt-cite key="bansal_revisiting_2021"></dt-cite>. While there is
          debate and complexity in this field
          <dt-cite key="Klabunde2023TowardsMR"></dt-cite>, these findings
          suggest a common representational substrate across models.
        </div>
      </li>
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-shield-halved"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Attack transferability:</b> Red-teaming and jailbreak prompts often
          transfer across different models, including black-box ones
          <dt-cite key="zou_universal_2023"></dt-cite>
          <dt-cite key="andriushchenko_jailbreaking_2024"></dt-cite>
          <dt-cite key="chao_jailbreaking_2024"></dt-cite>
          <dt-cite key="mehrotra_tree_2024"></dt-cite>. Such robustness of
          attacks may be due to underlying shared representational patterns,
          indicating that multiple models rely on similar internal structures.
        </div>
      </li>
      <li
        style="
          margin-bottom: 1.5em;
          display: flex;
          gap: 1em;
          align-items: baseline;
        ">
        <i
          class="fas fa-layer-group"
          style="color: #666; width: 1.5em; text-align: center"></i>
        <div>
          <b>Mechanistic interpretability (MI) and feature superposition:</b>
          The feature superposition theory
          <dt-cite key="anthropic"></dt-cite> suggests that multiple semantic
          features may be entangled within individual neurons, hinting at
          underlying "platonic" semantic features. Sparse Autoencoders (SAEs)
          <dt-cite key="cunningham_sparse_2023"></dt-cite> further support the
          idea of universal features that different models might compress
          differently.
        </div>
      </li>
    </ul>
    <p>
      At the same time
      <b
        >Representational similarity tools are becoming mature enough to explore
        such questions more deeply and empirically</b
      >
      and are percolating across both the machine learning and neuroscience
      communities
      <dt-cite
        key="sucholutsky2024gettingalignedrepresentationalalignment"></dt-cite
      >. For example, in
      <a href="https://representational-alignment.github.io/"
        >ICLR there was a workshop in the year of writing this (2024)</a
      >. Techniques such as CKA
      <dt-cite key="kornblith_similarity_2019"></dt-cite>, stitching
      <dt-cite key="bansal2021revisitingmodelstitchingcompare"></dt-cite>, CCA,
      <dt-cite key="ling2021nearoptimalboundsgeneralizedorthogonal"></dt-cite>
      Orthogonal Procrustes, and others, along with representational similarity
      analysis in neuroscience
      <dt-cite key="haxby_decoding_2014"></dt-cite>
      <dt-cite key="kriegeskorte_representational_2008"></dt-cite>
      <dt-cite key="yousefnezhad_deep_2021"></dt-cite>, have matured, making it
      feasible to systematically investigate such questions.
    </p>

    <h2 id="methodology">03 Methodology</h2>
    <!-- TODO: Make an actual methodology-overview -->
    <h3 id="methodology-overview">Overview</h3>

    <p>
      Our investigation into embedding model similarity followed a systematic
      experimental approach spanning multiple model architectures, embedding
      spaces, and datasets. The methodology consists of four main components:
      model selection, dataset selection, stitch architecture design, evaluation
      framework, and embedding parameter configuration.
    </p>

    <!-- TODO: Produce a table indicating cartesian product of models x datasets x ?? idk I guess this is fine.-->

    <ol>
      <li>
        <h3 id="model-selection">Embedding Model Selection</h3>
        We evaluated translation quality across several
        <b>embedding models</b> available on huggingface and via the OpenAI API.
        These models were selected to match the most similar prior work from
        <i>Beyond Benchmarks</i> for comparability and reproduceability. We also
        excluded the Cohere models since we did not have API access (which is
        not free except at prohibitively low request rates) and the Mistral
        model, since it was too big for our GPU.
        <details>
          <summary
            style="
              cursor: pointer;
              padding: 8px;
              background-color: #f5f5f5;
              border: 1px solid #ddd;
              border-radius: 4px;
              margin-bottom: 8px;
              margin-top: 20px;
            ">
            <i class="fas fa-code" style="margin-right: 8px"></i>View Model
            Names
          </summary>
          <pre><code class="language-python">
          MODEL_NAMES = [
          # MODEL_NAME                    EMBEDDING DIMENSION
          "WhereIsAI/UAE-Large-V1",                    # 1024
          "BAAI/bge-base-en-v1.5",                     # 768
          "BAAI/bge-large-en-v1.5",                    # 1024
          "BAAI/bge-small-en-v1.5",                    # 384
          "intfloat/e5-base-v2",                       # 768
          "intfloat/e5-large-v2",                      # 1024
          "intfloat/e5-small-v2",                      # 384
          "thenlper/gte-base",                         # 768
          "thenlper/gte-large",                        # 1024
          "thenlper/gte-small",                        # 384
          "sentence-transformers/gtr-t5-base",         # 768
          "sentence-transformers/gtr-t5-large",        # 768
          "mixedbread-ai/mxbai-embed-large-v1",        # 1024
          "sentence-transformers/sentence-t5-base",     # 768
          "sentence-transformers/sentence-t5-large",    # 768
          "openai/text-embedding-3-large",             # 3072
          "openai/text-embedding-3-small",             # 1536
          ]
        </code></pre>
        </details>
      </li>

      <b>Detailed Model Comparison Table</b>
      <div class="l-body l-body" style="margin-top: 1em">
        <!-- Tab Navigation -->
        <div class="model-tabs" style="margin-bottom: 1em">
          <button
            class="tab-button active important"
            onclick="showModelView('category')">
            <i
              class="fas fa-layer-group"
              style="color: #666; width: 1.5em; text-align: center"></i>
            By Architecture
          </button>
          <button class="tab-button" onclick="showModelView('dimension')">
            <i
              class="fas fa-arrows-alt-v"
              style="color: #666; width: 1.5em; text-align: center"></i>
            By Dimension
          </button>
          <button class="tab-button" onclick="showModelView('parameters')">
            <i
              class="fas fa-microchip"
              style="color: #666; width: 1.5em; text-align: center"></i>
            By Parameters
          </button>
        </div>

        <!-- Tab Content -->
        <div class="model-content">
          <!-- Category View (Original) -->
          <div class="tab-content active" id="category-content">
            <div style="overflow-x: auto">
              <!-- Original table content -->
              <table style="width: 100%; border-collapse: collapse">
                <thead>
                  <tr>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Model Family
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Variant
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Architecture
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Dimension
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Parameters
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Training Data
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <!-- BAAI BGE -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td style="padding: 8px" rowspan="3"><b>BAAI BGE</b></td>
                    <td>large-v1.5</td>
                    <td style="padding: 8px" rowspan="3">DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td style="padding: 8px" rowspan="3">330M+ text pairs</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>base-v1.5</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">110M</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>small-v1.5</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td style="text-align: center; padding: 8px">33M</td>
                  </tr>

                  <!-- E5 -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td style="padding: 8px" rowspan="3"><b>E5</b></td>
                    <td>large-v2</td>
                    <td style="padding: 8px" rowspan="3">DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td style="padding: 8px" rowspan="3">CCNet + web data</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>base-v2</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">110M</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>small-v2</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td style="text-align: center; padding: 8px">33M</td>
                  </tr>

                  <!-- GTE -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td style="padding: 8px" rowspan="3"><b>GTE</b></td>
                    <td>large</td>
                    <td style="padding: 8px" rowspan="3">DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td style="padding: 8px" rowspan="3">
                      MS MARCO + public datasets
                    </td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>base</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">110M</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>small</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td style="text-align: center; padding: 8px">33M</td>
                  </tr>

                  <!-- T5-based -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td style="padding: 8px" rowspan="4"><b>T5-based</b></td>
                    <td>gtr-t5-large</td>
                    <td style="padding: 8px" rowspan="4">T5 encoder</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">770M</td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>gtr-t5-base</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">110M</td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>sentence-t5-large</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">770M</td>
                    <td>C4 + NLI datasets</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>sentence-t5-base</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td style="text-align: center; padding: 8px">220M</td>
                    <td>C4 + NLI datasets</td>
                  </tr>

                  <!-- UAE -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td><b>UAE</b></td>
                    <td>large-v1</td>
                    <td>RoBERTa</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td style="text-align: center; padding: 8px">355M</td>
                    <td>Adversarial training</td>
                  </tr>

                  <!-- MXBai -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td><b>MXBai</b></td>
                    <td>embed-large-v1</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td>700M+ pairs contrastive training, 30M+ fine tuning</td>
                  </tr>

                  <!-- OpenAI -->
                  <tr style="border-bottom: 1px solid #eee">
                    <td style="padding: 8px" rowspan="2"><b>OpenAI</b></td>
                    <td>text-embedding-3-large</td>
                    <td style="padding: 8px" rowspan="2">Proprietary</td>
                    <td style="text-align: center; padding: 8px">3072</td>
                    <td style="text-align: center; padding: 8px">-</td>
                    <td style="padding: 8px" rowspan="2">Not public</td>
                  </tr>
                  <tr style="border-bottom: 1px solid #eee">
                    <td>text-embedding-3-small</td>
                    <td style="text-align: center; padding: 8px">1536</td>
                    <td style="text-align: center; padding: 8px">-</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <!-- Dimension View -->
          <div class="tab-content" id="dimension-content">
            <div style="overflow-x: auto">
              <table style="width: 100%; border-collapse: collapse">
                <thead>
                  <tr>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Model Family
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Variant
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Architecture
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Dimension
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Parameters
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Training Data
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <!-- 3072 dimension -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f8f0ff;
                    ">
                    <td><b>OpenAI</b></td>
                    <td>text-embedding-3-large</td>
                    <td>Proprietary</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #6200ee;
                      ">
                      3072
                    </td>
                    <td style="text-align: center; padding: 8px">-</td>
                    <td>Not public</td>
                  </tr>

                  <!-- 1536 dimension -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f5f5ff;
                    ">
                    <td><b>OpenAI</b></td>
                    <td>text-embedding-3-small</td>
                    <td>Proprietary</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #3700b3;
                      ">
                      1536
                    </td>
                    <td style="text-align: center; padding: 8px">-</td>
                    <td>Not public</td>
                  </tr>

                  <!-- 1024 dimension -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f0f0ff;
                    ">
                    <td><b>UAE</b></td>
                    <td>large-v1</td>
                    <td>RoBERTa</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">355M</td>
                    <td>Adversarial training</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f0f0ff;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>large-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f0f0ff;
                    ">
                    <td><b>E5</b></td>
                    <td>large-v2</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f0f0ff;
                    ">
                    <td><b>GTE</b></td>
                    <td>large</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td>MS MARCO + public datasets</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f0f0ff;
                    ">
                    <td><b>MXBai</b></td>
                    <td>embed-large-v1</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">335M</td>
                    <td>700M+ pairs contrastive training, 30M+ fine tuning</td>
                  </tr>

                  <!-- 768 dimension -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td style="padding: 8px" rowspan="4"><b>T5-based</b></td>
                    <td>gtr-t5-large</td>
                    <td style="padding: 8px" rowspan="4">T5 encoder</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">770M</td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td>gtr-t5-base</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #283593;
                      ">
                      768
                    </td>
                    <td style="text-align: center; padding: 8px">110M</td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td>sentence-t5-large</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1a237e;
                      ">
                      1024
                    </td>
                    <td style="text-align: center; padding: 8px">770M</td>
                    <td>C4 + NLI datasets</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td>sentence-t5-base</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #283593;
                      ">
                      768
                    </td>
                    <td style="text-align: center; padding: 8px">220M</td>
                    <td>C4 + NLI datasets</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>base-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #283593;
                      ">
                      768
                    </td>
                    <td style="text-align: center; padding: 8px">110M</td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td><b>E5</b></td>
                    <td>base-v2</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #283593;
                      ">
                      768
                    </td>
                    <td style="text-align: center; padding: 8px">110M</td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e8eaf6;
                    ">
                    <td><b>GTE</b></td>
                    <td>base</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #283593;
                      ">
                      768
                    </td>
                    <td style="text-align: center; padding: 8px">110M</td>
                    <td>MS MARCO + public datasets</td>
                  </tr>

                  <!-- 384 dimension -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e3f2fd;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>small-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      384
                    </td>
                    <td style="text-align: center; padding: 8px">33M</td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e3f2fd;
                    ">
                    <td><b>E5</b></td>
                    <td>small-v2</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      384
                    </td>
                    <td style="text-align: center; padding: 8px">33M</td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #e3f2fd;
                    ">
                    <td><b>GTE</b></td>
                    <td>small</td>
                    <td>DeBERTa-V3</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      384
                    </td>
                    <td style="text-align: center; padding: 8px">33M</td>
                    <td>MS MARCO + public datasets</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <!-- Parameters View -->
          <div class="tab-content" id="parameters-content">
            <div style="overflow-x: auto">
              <table style="width: 100%; border-collapse: collapse">
                <thead>
                  <tr>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Model Family
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Variant
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Architecture
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Dimension
                    </th>
                    <th
                      style="
                        text-align: center;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Parameters
                    </th>
                    <th
                      style="
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                      ">
                      Training Data
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <!-- OpenAI Variants with Highest Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #fff8e1;
                    ">
                    <td><b>OpenAI</b></td>
                    <td>text-embedding-3-large</td>
                    <td>Proprietary</td>
                    <td style="text-align: center; padding: 8px">3072</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #ff6f00;
                      ">
                      ?
                    </td>
                    <td>Not public</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #fff8e1;
                    ">
                    <td><b>OpenAI</b></td>
                    <td>text-embedding-3-small</td>
                    <td>Proprietary</td>
                    <td style="text-align: center; padding: 8px">1536</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #ff6f00;
                      ">
                      ?
                    </td>
                    <td>Not public</td>
                  </tr>

                  <!-- 770M Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f8f0ff;
                    ">
                    <td><b>T5-based</b></td>
                    <td>gtr-t5-large</td>
                    <td>T5 encoder</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #6200ee;
                      ">
                      770M
                    </td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #f8f0ff;
                    ">
                    <td><b>T5-based</b></td>
                    <td>sentence-t5-large</td>
                    <td>T5 encoder</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #6200ee;
                      ">
                      770M
                    </td>
                    <td>C4 + NLI datasets</td>
                  </tr>

                  <!-- 355M Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c8e6c9;
                    ">
                    <td><b>UAE</b></td>
                    <td>large-v1</td>
                    <td>RoBERTa</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #2e7d32;
                      ">
                      355M
                    </td>
                    <td>Adversarial training</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c8e6c9;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>large-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #2e7d32;
                      ">
                      335M
                    </td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c8e6c9;
                    ">
                    <td><b>E5</b></td>
                    <td>large-v2</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #2e7d32;
                      ">
                      335M
                    </td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c8e6c9;
                    ">
                    <td><b>GTE</b></td>
                    <td>large</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #2e7d32;
                      ">
                      335M
                    </td>
                    <td>MS MARCO + public datasets</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c8e6c9;
                    ">
                    <td><b>MXBai</b></td>
                    <td>embed-large-v1</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">1024</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #2e7d32;
                      ">
                      335M
                    </td>
                    <td>700M+ pairs contrastive training, 30M+ fine tuning</td>
                  </tr>

                  <!-- 220M Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #bbdefb;
                    ">
                    <td><b>T5-based</b></td>
                    <td>gtr-t5-base</td>
                    <td>T5 encoder</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1565c0;
                      ">
                      110M
                    </td>
                    <td>C4 + MS MARCO</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #bbdefb;
                    ">
                    <td><b>T5-based</b></td>
                    <td>sentence-t5-base</td>
                    <td>T5 encoder</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #1565c0;
                      ">
                      220M
                    </td>
                    <td>C4 + NLI datasets</td>
                  </tr>

                  <!-- 110M Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c5cae9;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>base-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      110M
                    </td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c5cae9;
                    ">
                    <td><b>E5</b></td>
                    <td>base-v2</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      110M
                    </td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #c5cae9;
                    ">
                    <td><b>GTE</b></td>
                    <td>base</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">768</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      110M
                    </td>
                    <td>MS MARCO + public datasets</td>
                  </tr>

                  <!-- 33M Parameters -->
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #bbdefb;
                    ">
                    <td><b>BAAI BGE</b></td>
                    <td>small-v1.5</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      33M
                    </td>
                    <td>330M+ text pairs</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #bbdefb;
                    ">
                    <td><b>E5</b></td>
                    <td>small-v2</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      33M
                    </td>
                    <td>CCNet + web data</td>
                  </tr>
                  <tr
                    style="
                      border-bottom: 1px solid #eee;
                      background-color: #bbdefb;
                    ">
                    <td><b>GTE</b></td>
                    <td>small</td>
                    <td>DeBERTa-V3</td>
                    <td style="text-align: center; padding: 8px">384</td>
                    <td
                      style="
                        text-align: center;
                        padding: 8px;
                        font-weight: bold;
                        color: #0d47a1;
                      ">
                      33M
                    </td>
                    <td>MS MARCO + public datasets</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>

      <script>
        function showModelView(viewId) {
          // Hide all content
          document
            .querySelectorAll(".model-content .tab-content")
            .forEach((content) => {
              content.classList.remove("active");
            });

          // Show selected content
          document.getElementById(viewId + "-content").classList.add("active");

          // Update button states
          document
            .querySelectorAll(".model-tabs .tab-button")
            .forEach((button) => {
              button.classList.remove("active");
            });
          document
            .querySelector(`.model-tabs [onclick="showModelView('${viewId}')"]`)
            .classList.add("active");
        }
      </script>

      <!-- Reuse existing tab styles -->
      <style>
        .model-tabs {
          display: flex;
          gap: 0.5em;
          border-bottom: 1px solid #ddd;
          padding-bottom: 0.5em;
        }

        /* Reuse other existing tab styles */
      </style>

      <li>
        <h3 id="dataset-selection">Dataset Selection</h3>
        Each dataset we tested was one of the MTEB embedding language model
        datasets
        <dt-cite key="muennighoff2023mtebmassivetextembedding"></dt-cite>
        chosen for their relevancy to many embedding tasks. Each dataset spans
        thousands of short documents. Unlike the <i>Beyond Baselines</i> paper,
        we randomly shortened each dataset to a maximum of 20K documents train
        and 5K documents validation, since we were computationally constrained
        for this project.
        <!-- TODO: @Adriano, explain what happened here. -->
        <details>
          <summary class="details-summary">
            <i class="fas fa-code icon-common"></i>View Dataset Names
          </summary>
          <pre><code class="language-python">
          DATASETS = [
            "arguana",    # Around 10K Short documents
            "fiqa",       # Around 50K, shortened to 20K
            "scidocs",    # Around 25K, shortened to 20K
            "nfcorpus",   # Around 5K
            "hotpotqa",   # Over 100K, shortened to 20K
            "trec-covid", # At least 20K, shortened to 20K
          ]
        </code></pre>
        </details>

        <p>You can read more about the datasets below:</p>
        <style>
          .dataset-descriptions details[open] .fa-chevron-right {
            transform: rotate(90deg);
          }
          .dataset-descriptions .fa-chevron-right {
            transition: transform 0.2s;
          }
        </style>

        <div class="dataset-descriptions">
          <ul style="list-style: none; padding-left: 0">
            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>ArguAna</b></div>
                  <i
                    class="fas fa-comments"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] Discussion icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A dataset of ~10K argument pairs from online discussions,
                  where each pair contains one argument in favor and one against
                  a given topic. Useful for evaluating semantic understanding of
                  argumentative text and stance detection.
                </div>
              </details>
            </li>

            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>FiQA</b></div>
                  <i
                    class="fas fa-chart-line"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] Finance icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A financial domain dataset containing ~50K text snippets from
                  financial news and social media platforms. Includes questions,
                  answers, and sentiment analysis annotations specific to
                  financial topics.
                </div>
              </details>
            </li>

            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>SciDocs</b></div>
                  <i
                    class="fas fa-flask"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] Science icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A collection of ~25K scientific documents and paper abstracts
                  from various fields. Designed to evaluate scientific document
                  understanding and recommendation systems.
                </div>
              </details>
            </li>

            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>NFCorpus</b></div>
                  <i
                    class="fas fa-heartbeat"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] Medical icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A dataset of ~5K medical documents from NLM (National Library
                  of Medicine), including clinical trials, systematic reviews,
                  and medical news articles. Used for evaluating biomedical
                  information retrieval.
                </div>
              </details>
            </li>

            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>HotpotQA</b></div>
                  <i
                    class="fas fa-question-circle"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] Q&A icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A large question-answering dataset with over 100K
                  question-answer pairs. Questions require finding and reasoning
                  over multiple supporting documents to arrive at the answer,
                  testing multi-hop inference capabilities.
                </div>
              </details>
            </li>

            <li style="margin-bottom: 1.5em">
              <details>
                <summary
                  style="
                    display: flex;
                    gap: 1em;
                    align-items: baseline;
                    cursor: pointer;
                  ">
                  <i
                    class="fas fa-chevron-right"
                    style="color: #666; width: 1em; text-align: center"></i>
                  <div><b>TREC-COVID</b></div>
                  <i
                    class="fas fa-virus"
                    style="color: #666; width: 1.5em; text-align: center"></i>
                  <!-- [NEW] COVID icon -->
                </summary>
                <div style="margin-left: 2em; margin-top: 0.5em">
                  A dataset of ~20K scientific articles related to COVID-19 from
                  the CORD-19 collection. Includes queries from biomedical
                  researchers about COVID-19 and relevant document judgments,
                  designed to evaluate biomedical literature search systems.
                </div>
              </details>
            </li>
          </ul>
        </div>
      </li>

      <li>
        <h3 id="translation-architecture">Stitch Architecture</h3>
        <p>
          We implemented stitch functions using Ordinary Least Squares (OLS) to
          find a best fitting affine function transforming the source embeddings
          to the target embeddings. Originally, this was to be a baseline
          accuracy, and we intended to try more complicated functions but it was
          unnecessary for high accuracy as shown below.
        </p>
        <p>
          <!-- Maybe move to a future work section? -->
          Future work may explore how non-linearities and more complex functions
          could improve accuracy, for which there is reason to believe. Consider
          that, as an embedding model is trained on more data, regions of an
          embedding space may experience non-linear expansion as certain related
          concepts tend to disentangle or as the relationship between different
          concepts changes such that there exists no affine mapping from the
          model earlier in training and the model later in training. This would
          make sense, considering there is a qualitative difference between
          embeddings of more sophisticated models and less sophisticated ones, a
          an exclusively linear mapping would not make sense.
        </p>
        <p>
          Future work could also consider optimizing over even simpler
          transformations, such as rigid rotations (linear isometries)
          permutations to better quantify the connectivity-alignment of
          different embedding spaces.
          <!-- Why isometric? Embedding space B could just be embedding space A
       scaled x2 but maybe regularization beats this out idk. Uncertain whether to simpler transform is cash money. -->
        </p>
      </li>
      <!-- TODO: Add math everywhere ig -->
      <li>
        <h3 id="evaluation-metric">Evaluation Metrics</h3>
        <p>
          We considered a range of different metrics to analyze the relationship
          between embedding spaces, settling on a mix from our reference paper,
          statistics on the stiching models bridging two embedding spaces, and
          some visualizaitons to better understand exactly what these stitches
          are doing.
        </p>

        <ul>
          <li
            style="
              margin-bottom: 1.5em;
              display: flex;
              gap: 1em;
              align-items: baseline;
            ">
            <i
              class="fas fa-chart-bar"
              style="color: #666; width: 1.5em; text-align: center"></i>
            <div>
              Our <b>embedding similarity metrics</b> aimed corroborate the work
              in our reference paper:
              <i
                >Beyond Benchmarks: Evaluating Embedding Model Similarity for
                Retrieval Augmented Generation Systems</i
              >
              <dt-cite
                key="caspari2024benchmarksevaluatingembeddingmodel"></dt-cite
              >. We look primarily into
              <a
                href="http://datumorphism.leima.is/cards/machine-learning/measurement/centered-kernel-alignment/"
                ><b>CKA (Centered Kernel Alignment)</b></a
              >
              <!-- We look into the same <b>CKA</b>, <b>Rank</b>, and <b>Jaccard Index</b> metrics to -->
              <!-- https://datumorphism.leima.is/cards/machine-learning/measurement/centered-kernel-alignment/ -->
              <!-- TODO: Rank and Jaccard Index, also maybe Adriano can explain this -->
              , a metric to measure the similarity between feature
              representations between neural networks. We compare these metrics
              with the past results and against those of the stitched
              embeddings. That is to say, if on a single datset we stitch the
              embeddings of model \(A\) to the embeddings of model \(B\) then we
              look at the CKA, Rank, and Jaccard Index of the image of the map
              with the embeddings from model \(B\).
              <!-- TODO: This last part of doing the stitched embeddings -->
            </div>
          </li>
          <!-- Note: Adriano maybe wants to swap intial with linear connectivity -->
          <li
            style="
              margin-bottom: 1.5em;
              display: flex;
              gap: 1em;
              align-items: baseline;
            ">
            <i
              class="fas fa-ruler"
              style="color: #666; width: 1.5em; text-align: center"></i>
            <div>
              Our <b>linear connectivity-alignment metrics</b> are the train and
              validation accuracy of our stitching models, which we measure by
              <b>Mean Squared Error (MSE)</b>. To make this more interpretable,
              we also provide: <b>mean absolute error (MAE)</b> on the
              validation set, explained <b>variance ratio</b> between the
              stitched embeddings and the target embeddings,
              <!-- TODO? -->
              explained <b>absolute variation</b>
              between the stitched embeddings and the target embeddings. We also
              plot
              <!-- TODO? -->
              the <b>eigenvalues/singular values</b> of the stitched embeddings
              and compare their affine shifts to the means of the embedding
              datasets. This helps us qualitatively estimate whether the
              embedding matrix may actually belong to a simpler class, such as a
              rotation.
              <!-- TODO -->
            </div>
          </li>
          <li
            style="
              margin-bottom: 1.5em;
              display: flex;
              gap: 1em;
              align-items: baseline;
            ">
            <i
              class="fas fa-eye"
              style="color: #666; width: 1.5em; text-align: center"></i>
            <div>
              Our <b>interpretation visualizations</b> include a <b>UMAP</b>.
              <!--<b>PCA</b>, and
            <b>t-SNE</b> visualization of the embeddings both before and after applying
            the stitching function. -->
              <!-- TODO: Fairly sure we are changing to visualize cycles or smthn -->
              <!-- We use a clustering algorithm and partially
            automated labeling to help illustrate whether the stitching function
            preserves relations. We compare the clusters both before stitching,
            after stitching, and for the target embeddings. We also include a few
            kernel tables randomly chosen and cherry-picked to illustrate, from
            another angle, whether relations are preserved. -->
            </div>
          </li>
          <!-- <li>Generating embeddings on test datasets</li> -->
        </ul>
      </li>
      <li>
        <h3 id="embedding-parameters">Embedding Parameters</h3>
        <p>
          We used the parameters illustrated below for our embedding models. The
          datasets are comprised of documents and sample queries (for
          reproduceable top-K search results analysis). We embed each seperately
          appending a prefix as visible below, like in the prior work. Unlike
          the prior work we use an OpenAI text splitter with a fixed model. This
          allows us to ensure that we compare the exact same text's emebeddings
          across models --- a subtle bug that we reported to the authors of
          <i>Beyond Benchmarks</i>
          <dt-cite
            key="caspari2024benchmarksevaluatingembeddingmodel"></dt-cite>
          though we do not find qualitatively different results before linearly
          connecting the embedding spaces. As previously mentioned, we reduce
          and split both query and document datasets to up to 20K and 5K
          documents respectively. Then, we chunk each document into at least one
          chunk and embed each chunk with each model. The default
          <a href="https://huggingface.co/sentence-transformers"
            >SentenceTransformers</a
          >
          <code class="language-python">encode</code> function is used.
        </p>
        <pre><code class="language-python">
        VECTOR_SEARCH_SENTENCE_DEFAULT_CHUNK_SIZE=256
        VECTOR_SEARCH_DISTANCE_FUNCTION="cosine"
        VECTOR_SEARCH_NORMALIZE_EMBEDDINGS="true"
        VECTOR_SEARCH_CHUNK_PREFIX="passage: "
        VECTOR_SEARCH_QUERY_PREFIX="query: "
        VECTOR_SEARCH_TEXT_SPLITTER_CHUNK_OVERLAP=25
        BATCH_SIZE=64
        CHUNK_SIZE=256
    </code></pre>
      </li>
    </ol>

    <h2 id="results">04 Results and Analysis</h2>
    <p>
      We conducted extensive experiments across different model scales and
      architectures. Here are our key findings:
    </p>

    <h3 id="results-measuring-sim">Measuring Representational Similarity</h3>
    <figure>
      <iframe
        src="figs/cka_matrix_on_arguana.html"
        width="800"
        height="600"
        frameborder="0"
        scrolling="no"></iframe>
      <figcaption>
        CKA Matrix measuring representational similarity between embedding
        models with text sampled from ArguAna. Note that the larger OpenAI
        models were excluded from this metric due to time constraints.
      </figcaption>
    </figure>

    <p>
      In line with the metrics presented in <i>Beyond Benchmarks</i>, we
      examined the pairwise similarity between our various embedding models.
      Above you can see our
      <a
        href="http://datumorphism.leima.is/cards/machine-learning/measurement/centered-kernel-alignment/"
        ><b>CKA (Centered Kernel Alignment)</b></a
      >
      matrix. This is a simple common metric to measure the similarity between
      representations. To do this, you start with a text dataset which are fed
      through the embedding models \(A\) and \(B\) to produce sample embeddings
      \(Z_A\) and \(Z_B\). These embeddings are then compared.
      <!-- finish description -->
      Scores closer to \(1\) are more similar and scores closer to \(0\) are
      less similar. In our matrix we also introduced a control "embedding" model
      which was a (ArguAna Length \(\times 768\) embedding dimension) standard
      gaussian matrix not included in the reference paper.
      <!-- idk if this explanation is required but word count go brr I guess -->
      <!-- Also I think the control was dimensionality 768? -->
      <!-- Also heck this matrix may be messed up? GAAHH -->
      <!-- Do these support or line up with Beyond Benchmarks? -->
    </p>

    <p>
      As you can hope to see, the random embedding model is extremely dissimilar
      from other embeddings, getting a similarity score of only \(0.10\) to
      \(0.16\) while the strongest similarities are all the way up to \(1.00\)
      (Approximately-complete similarity) between mxbai-embed-large-v1 and
      UAE-Large-V1, models from different companies, both with embedding
      dimension \(1024\). Just looking at these preliminary similarity scores,
      we hypothesize that these two models have stitch-connectivity.
    </p>

    <p>
      The lowest similarity we observe is \(0.72\) between bge-small-en-v1.5 and
      e5-large-v2 of dimensions \(384\) and \(1024\) respectively. Still quite a
      high similarity in representations. We hypothesized models differing in
      scale such as these would have a lower representational similarity and
      hypothesize that these two models will not have stitch-connectivity.
    </p>

    <!-- A measurement of cka per difference in their dimensionality helpful? -->

    <p>
      Unfortunately, we were unable to evaluate the OpenAI models due to time
      constraints, but we would expect that the CKA values between these models
      of even higher scale and dimensionality than e5-large-v2 will have even
      less similarity with a smaller model like bge-small-en-v1.5. We
      hypothesize that, when we analyze the stitch connectivity, that the MSE
      will be even higher between bge-small-en-v1.5 and our largest model,
      openai/text-embedding-3-large with dimension \(3072\).
    </p>

    <h3 id="results-measuring-connectivity">Measuring Stitch-Connectivity</h3>
    <hr />
    <div class="l-screen-inset" style="margin-left: 5em">
      <!-- Tab Navigation -->
      <b style="margin-bottom: 1em"
        >Validation MSE and MAE of Affine Stitch Across Datasets</b
      >
      <div class="dataset-tabs" style="margin-bottom: 1em">
        <button
          class="tab-button active important"
          onclick="showDataset('average')">
          <i
            class="fas fa-calculator"
            style="color: #666; width: 1.5em; text-align: center"></i>
          Weighted Average
        </button>
        <button class="tab-button" onclick="showDataset('arguana')">
          <i
            class="fas fa-comments"
            style="color: #666; width: 1.5em; text-align: center"></i>
          ArguAna
        </button>
        <button class="tab-button" onclick="showDataset('fiqa')">
          <i
            class="fas fa-chart-line"
            style="color: #666; width: 1.5em; text-align: center"></i>
          FiQA
        </button>
        <button class="tab-button" onclick="showDataset('scidocs')">
          <i
            class="fas fa-flask"
            style="color: #666; width: 1.5em; text-align: center"></i>
          SciDocs
        </button>
        <button class="tab-button" onclick="showDataset('nfcorpus')">
          <i
            class="fas fa-heartbeat"
            style="color: #666; width: 1.5em; text-align: center"></i>
          NFCorpus
        </button>
        <button class="tab-button" onclick="showDataset('hotpotqa')">
          <i
            class="fas fa-question-circle"
            style="color: #666; width: 1.5em; text-align: center"></i>
          HotpotQA
        </button>
        <button class="tab-button" onclick="showDataset('trec-covid')">
          <i
            class="fas fa-virus"
            style="color: #666; width: 1.5em; text-align: center"></i>
          TREC-COVID
        </button>
      </div>

      <!-- Tab Content -->
      <div class="dataset-content">
        <style>
          .dataset-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2em;
            max-width: 100%;
            margin: 0 auto;
          }

          .dataset-grid figure {
            margin: 0;
            width: 100%;
          }

          .dataset-grid iframe {
            width: 100%;
            height: 600px;
            border: none;
          }

          .dataset-grid figcaption {
            margin-top: 1em;
            text-align: center;
            color: #666;
          }
        </style>

        <!-- Weighted Average -->
        <div class="tab-content active" id="average-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/weightedmean_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - Weighted Average
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/weightedmean_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - Weighted Average
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- ArguAna -->
        <div class="tab-content" id="arguana-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/arguana_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - ArguAna Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/arguana_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - ArguAna Dataset
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- FiQa -->
        <div class="tab-content" id="fiqa-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/fiqa_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - FiQA Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/fiqa_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - FiQA Dataset
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- SciDocs -->
        <div class="tab-content" id="scidocs-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/scidocs_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - SciDocs Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/scidocs_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - SciDocs Dataset
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- NfCorpus -->
        <div class="tab-content" id="nfcorpus-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/nfcorpus_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - NFCorpus Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/nfcorpus_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - NFCorpus Dataset
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- HotPot QA -->
        <div class="tab-content" id="hotpotqa-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/hotpotqa_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - HotpotQA Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/hotpotqa_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - HotpotQA Dataset
              </figcaption>
            </figure>
          </div>
        </div>

        <!-- TrecCovid -->
        <div class="tab-content" id="trec-covid-content">
          <div class="dataset-grid">
            <figure>
              <b>Mean Squared Error (MSE)</b>
              <iframe
                src="./figs/adriano/figs/html/trec-covid_olsaffine_mse_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Squared Error (MSE) loss visualization across model pairs
                (Training Objective) - TREC-COVID Dataset
              </figcaption>
            </figure>
            <figure>
              <b>Mean Absolute Error (MAE)</b>
              <iframe
                src="./figs/adriano/figs/html/trec-covid_olsaffine_mae_withlog_validation.html"
                scrolling="no"></iframe>
              <figcaption>
                Mean Absolute Error (MAE) loss visualization across model pairs
                - TREC-COVID Dataset
              </figcaption>
            </figure>
          </div>
        </div>
      </div>
    </div>

    <script>
      function showDataset(datasetId) {
        // Hide all content
        document.querySelectorAll(".tab-content").forEach((content) => {
          content.classList.remove("active");
        });

        // Show selected content
        document.getElementById(datasetId + "-content").classList.add("active");

        // Update button states
        document.querySelectorAll(".tab-button").forEach((button) => {
          button.classList.remove("active");
        });
        document
          .querySelector(`[onclick="showDataset('${datasetId}')"]`)
          .classList.add("active");
      }
    </script>
    <hr />
    <p>
      <i
        >Note: The axis labels are not in the same order as in the CKA
        matrix.</i
      >
    </p>

    <p><b>At a Distance</b></p>

    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_top_performing.png"
          alt="Top performing stitches." />
        <figcaption>Top performing stitches</figcaption>
      </figure>
    </div>

    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_worst_performing.png"
          alt="Least compatible native embedding space and worst performing stitches." />
        <figcaption>
          Least compatible native embedding space and worst performing stitches.
        </figcaption>
      </figure>
    </div>

    <p>
      The plots above show the log mean errors in stitching from embeddings of
      the source model (x-axis) to embeddings of the target model (y-axis) using
      our OLS-derived affine function.
    </p>

    <p>
      Overall, the affine stitches performed fairly well, ranging from a log MSE
      of \(-5.63\) (0.35% MSE) to \(-3.16\) (4.24% MSE).
    </p>

    <p>The top four performing stitches were:</p>
    <ol>
      <li>(\(-5.63\)) mxbai-embed-large-v1 to UAE-Large-V1</li>
      <li>(\(-5.62\)) UAE-Large-V1 to mxbai-embed-large-v1</li>
      <li>(\(-5.12\)) UAE-Large-V1 to bge-large-en-v1.5</li>
      <li>(\(-5.11\)) bge-large-en-v1.5 to UAE-Large-V1</li>
    </ol>

    <p>
      All of these models are of dimension \(1024\) and and we had hypothesized
      that they would do fairly well.
    </p>

    <p>
      The bottom four performing stitches were all unsurprisingly stitched from
      bge-small-en-v1.5, one of our two smallest models with dimension \(384\).
      We had hypothesized that this would be the case. The only decently
      performing stitch with this native space was bge-small-en-v1.5 to
      gte-small, another model of dimension \(384\). This too is unsurprising.
    </p>

    <p>
      However, what caught us off guard is that stitches from gte-small to other
      embedding spaces performed on-par with models that were far larger,
      including OpenAI's text-embedding-3-small, a model nearly 4 times its
      size. If text-emedding-3-small was storing a more expressive
      representation of semantic features than text-embedding-3-small, then how
      come affine stitches had similar performance when operating from their
      embeddings? How come bge-small-en-v1.5
    </p>

    <!-- <p>
    Calling back to our predictions from CKA in the previous section,
  </p> -->

    <p><b>Native Space Performance</b></p>

    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_varying_native_uae_large.png"
          alt="Highest-variance native embedding space." />
        <figcaption>Highest-variance native embedding space.</figcaption>
      </figure>
    </div>

    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_largest_to_smallest.png"
          alt="Largest to smallest comparison." />
        <figcaption>Largest to smallest comparison.</figcaption>
      </figure>
    </div>

    <p><b>Target Space Performance</b></p>
    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_most_compatible_native.png"
          alt="Most compatible native embedding spaces." />
        <figcaption>Most compatible native embedding spaces.</figcaption>
      </figure>
    </div>
    <!-- Omg having a summary average column would be amazing + the random -->

    <div class="l-page side">
      <figure>
        <img
          src="./figs/MSE_expected_worst_target.png"
          alt="Expected worst stitch performance to highest quality embedding space." />
        <figcaption>
          Expected worst stitch performance to highest quality embedding space.
        </figcaption>
      </figure>
    </div>

    <!-- 
          MODEL_NAMES = [
        # MODEL_NAME                    EMBEDDING DIMENSION
        "WhereIsAI/UAE-Large-V1",                    # 1024
        "BAAI/bge-base-en-v1.5",                     # 768
        "BAAI/bge-large-en-v1.5",                    # 1024
        "BAAI/bge-small-en-v1.5",                    # 384
        "intfloat/e5-base-v2",                       # 768
        "intfloat/e5-large-v2",                      # 1024
        "intfloat/e5-small-v2",                      # 384
        "thenlper/gte-base",                         # 768
        "thenlper/gte-large",                        # 1024
        "thenlper/gte-small",                        # 384
        "sentence-transformers/gtr-t5-base",         # 768
        "sentence-transformers/gtr-t5-large",        # 768
        "mixedbread-ai/mxbai-embed-large-v1",        # 1024
        "sentence-transformers/sentence-t5-base",     # 768
        "sentence-transformers/sentence-t5-large",    # 768
        "openai/text-embedding-3-large",             # 3072
        "openai/text-embedding-3-small",             # 1536
        ]
  
  -->

    <h2 id="discussion">05 Discussion</h2>
    <p>
      Our experimental results revealed several key insights about semantic
      representation alignment in LLMs:
      <!-- Explore which datasets have better/worse loss -->
      <!-- Note: Maybe have a future work, maybe have a note regarding the tokenization bug that was found. -->
      <!-- Maybe I should talk about my universal UMAP idea. Having many 2D projections -->
    </p>

    <h2 id="conclusion">06 Conclusion</h2>
    <!-- Below was llm produced -->
    <!-- <p>
    Through extensive experimentation across multiple model architectures and
    scales, we have demonstrated that LLMs do indeed learn remarkably similar
    semantic representations, with translation quality reaching up to 0.89
    cosine similarity in optimal conditions. Our work provides strong empirical
    support for the Platonic Representation Hypothesis while also highlighting
    important limitations and variations across scales and domains.
  </p>

  <p>
    The practical implications of our findings are significant: organizations
    can potentially save substantial computational resources by translating
    existing embeddings rather than recomputing them with new models. We have
    released our translation models and evaluation framework to facilitate
    further research in this direction.
  </p> -->
  </dt-article>

  <dt-appendix>
    <h3>📚 Cite this work</h3>
    <p style="margin-bottom: 1em">
      If you found this work useful, please cite:
    </p>

    <div
      style="
        background: #f5f6f7;
        padding: 1.5em;
        border-radius: 8px;
        margin-bottom: 1em;
      ">
      <pre
        style="
          font-family:
            Consolas,
            Courier New,
            monospace;
          font-size: 0.9em;
          margin: 0;
          white-space: pre-wrap;
          word-wrap: break-word;
        ">
@article{culp_hern_embed_stitch_2024,
    title     = {The Alignment of Semantic Representations Across Language Models},
    author    = {Culp, Gatlen* and Hernandez, Adriano*}, 
    note      = {* Equal Contribution},
    journal   = {MIT Deep Learning Blogs},
    year      = {2024},
    month     = {dec},
    url       = {https://gatlen.notion.site/blog/semantic-alignment},
    abstract  = {Recent advances in Large Language Models (LLMs) have demonstrated their
                remarkable ability to capture and manipulate semantic information. This
                work investigates the extent to which different LLMs learn similar 
                semantic representations despite variations in architecture, training
                data, and initialization, revealing significant alignment between
                models' semantic spaces.}
}</pre
      >
    </div>

    <h3>💻 Use our code</h3>
    <p style="margin-top: 1.5em; font-size: 0.9em; color: #666">
      Our code will eventually be made public here:
      <a href="https://github.com/GatlenCulp/embedding_translation"
        >https://github.com/GatlenCulp/embedding_translation</a
      >
    </p>
  </dt-appendix>
</body>
